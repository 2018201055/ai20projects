```python
import torch
import torch.nn.functional as F
import hiddenlayer as hl
from torchkeras import summary
from keras.utils import plot_model
from tensorboardX import SummaryWriter
# import tensorwatch as tw
from pytorch2keras import converter
from torch.autograd import Variable
import numpy as np
import torch.nn as nn
import numpy as np
from torchvision import models

class Vgg_16(torch.nn.Module):

    def __init__(self):
        super(Vgg_16, self).__init__()
        self.convolution1 = torch.nn.Conv2d(1, 64, 3, padding=1)
        self.pooling1 = torch.nn.MaxPool2d(2, stride=2)
        self.convolution2 = torch.nn.Conv2d(64, 128, 3, padding=1)
        self.pooling2 = torch.nn.MaxPool2d(2, stride=2)
        self.convolution3 = torch.nn.Conv2d(128, 256, 3, padding=1)
        self.convolution4 = torch.nn.Conv2d(256, 256, 3, padding=1)
        self.pooling3 = torch.nn.MaxPool2d((1, 2), stride=(2, 1))
        self.convolution5 = torch.nn.Conv2d(256, 512, 3, padding=1)
        self.BatchNorm1 = torch.nn.BatchNorm2d(512)
        self.convolution6 = torch.nn.Conv2d(512, 512, 3, padding=1)
        self.BatchNorm2 = torch.nn.BatchNorm2d(512)
        self.pooling4 = torch.nn.MaxPool2d((1, 2), stride=(2, 1))
        self.convolution7 = torch.nn.Conv2d(512, 512, 2)

    def forward(self, x):
        x = F.relu(self.convolution1(x), inplace=True)
        x = self.pooling1(x)
        x = F.relu(self.convolution2(x), inplace=True)
        x = self.pooling2(x)
        x = F.relu(self.convolution3(x), inplace=True)
        x = F.relu(self.convolution4(x), inplace=True)
        x = self.pooling3(x)
        x = self.convolution5(x)
        x = F.relu(self.BatchNorm1(x), inplace=True)
        x = self.convolution6(x)
        x = F.relu(self.BatchNorm2(x), inplace=True)
        x = self.pooling4(x)
        x = F.relu(self.convolution7(x), inplace=True)
        return x


class RNN(torch.nn.Module):
    def __init__(self, class_num, hidden_unit):
        super(RNN, self).__init__()
        self.Bidirectional_LSTM1 = torch.nn.LSTM(512, hidden_unit, bidirectional=True)
        self.embedding1 = torch.nn.Linear(hidden_unit * 2, 512)
        self.Bidirectional_LSTM2 = torch.nn.LSTM(512, hidden_unit, bidirectional=True)
        self.embedding2 = torch.nn.Linear(hidden_unit * 2, class_num)

    def forward(self, x):
        x = self.Bidirectional_LSTM1(x)
        T, b, h = x[0].size()
        x = self.embedding1(x[0].view(T * b, h))
        x = x.view(T, b, -1)
        x = self.Bidirectional_LSTM2(x)
        T, b, h = x[0].size()
        x = self.embedding2(x[0].view(T * b, h))
        x = x.view(T, b, -1)
        return x


class CRNN(torch.nn.Module):
    def __init__(self, class_num, hidden_unit=256):
        super(CRNN, self).__init__()
        self.cnn = torch.nn.Sequential()
        self.cnn.add_module('vgg_16', Vgg_16())
        self.rnn = torch.nn.Sequential()
        self.rnn.add_module('rnn', RNN(class_num, hidden_unit))

    def forward(self, x):
        x = self.cnn(x)
        b, c, h, w = x.size()
        assert h == 1
        x = x.squeeze(2)
        x = x.permute(2, 0, 1)
        x = self.rnn(x)
        return x
```

```python
# hiddenlayer
model_1 = Vgg_16()
model_2 = RNN(class_num=10, hidden_unit=32)
model_3 = CRNN(class_num=10, hidden_unit=64)

hl_graph_1 = hl.build_graph(model_1, torch.zeros([4, 1, 512, 512]))
hl_graph_1.save(path='D:/Python/introduction to ai/Vgg_16.png')

hl_graph_2 = hl.build_graph(model_2, torch.zeros([2, 512, 512]))
hl_graph_2.save(path='D:/Python/introduction to ai/RNN.png')

hl_graph_3 = hl.build_graph(model_3, torch.zeros([64, 1, 32, 512]))
hl_graph_3.save(path='D:/Python/introduction to ai/CRNN.png')

# TensorboardX
model = Vgg_16()

dummy_input = torch.rand(2, 1, 512, 512)  # 假设输入2张1*512*512的图片
model = Vgg_16()
with SummaryWriter(comment='Vgg_16') as w:
    w.add_graph(model, (dummy_input,))

# pytorch2keras
model_1 = Vgg_16()
input_np_1 = np.random.uniform(0, 1, (4, 1, 512, 512))
input_var_1 = Variable(torch.FloatTensor(input_np_1))
model_1 = converter.pytorch_to_keras(model_1, input_var_1, verbose=True)
plot_model(model_1, to_file='D:/Python/introduction to ai/keras Vgg 16.png', show_shapes=True)

model_2 = RNN(class_num=10, hidden_unit=32)
input_np_2 = np.random.uniform(0, 1, (1, 512, 512))
input_var_2 = Variable(torch.FloatTensor(input_np_2))
model_2 = converter.pytorch_to_keras(model_2, input_var_2, [(1, 512, 512)], verbose=True)
plot_model(model_2, to_file='D:/Python/introduction to ai/keras RNN.png', show_shapes=True)

model_3 = CRNN(class_num=10, hidden_unit=64)
input_np_3 = np.random.uniform(0, 1, (64, 1, 32, 512))
input_var_3 = Variable(torch.FloatTensor(input_np_3))
model_3 = converter.pytorch_to_keras(model_3, input_var_3, [(64, 1, 32, 512)], verbose=True)
plot_model(model_3, to_file='D:/Python/introduction to ai/keras CRNN.png', show_shapes=True)
```

**以上为可视化VGG16、BiLSTM、CRNN的代码；此外，可视化CTPN的代码如下：**

```python
class Im2col(nn.Module):
    def __init__(self, kernel_size, stride, padding):
        super(Im2col, self).__init__()
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding

    def forward(self, x):
        height = x.shape[2]
        x = F.unfold(x, self.kernel_size, padding=self.padding, stride=self.stride)
        x = x.reshape((x.shape[0], x.shape[1], height, -1))
        return x


class VGG_16(nn.Module):
    def __init__(self):
        super(VGG_16, self).__init__()
        self.convolution1_1 = nn.Conv2d(3, 64, 3, padding=1)
        self.convolution1_2 = nn.Conv2d(64, 64, 3, padding=1)
        self.pooling1 = nn.MaxPool2d(2, stride=2)
        self.convolution2_1 = nn.Conv2d(64, 128, 3, padding=1)
        self.convolution2_2 = nn.Conv2d(128, 128, 3, padding=1)
        self.pooling2 = nn.MaxPool2d(2, stride=2)
        self.convolution3_1 = nn.Conv2d(128, 256, 3, padding=1)
        self.convolution3_2 = nn.Conv2d(256, 256, 3, padding=1)
        self.convolution3_3 = nn.Conv2d(256, 256, 3, padding=1)
        self.pooling3 = nn.MaxPool2d(2, stride=2)
        self.convolution4_1 = nn.Conv2d(256, 512, 3, padding=1)
        self.convolution4_2 = nn.Conv2d(512, 512, 3, padding=1)
        self.convolution4_3 = nn.Conv2d(512, 512, 3, padding=1)
        self.pooling4 = nn.MaxPool2d(2, stride=2)
        self.convolution5_1 = nn.Conv2d(512, 512, 3, padding=1)
        self.convolution5_2 = nn.Conv2d(512, 512, 3, padding=1)
        self.convolution5_3 = nn.Conv2d(512, 512, 3, padding=1)

        self.load_pretrain_model()

    def forward(self, x):
        x = F.relu(self.convolution1_1(x), inplace=True)
        x = F.relu(self.convolution1_2(x), inplace=True)
        x = self.pooling1(x)
        x = F.relu(self.convolution2_1(x), inplace=True)
        x = F.relu(self.convolution2_2(x), inplace=True)
        x = self.pooling2(x)
        x = F.relu(self.convolution3_1(x), inplace=True)
        x = F.relu(self.convolution3_2(x), inplace=True)
        x = F.relu(self.convolution3_3(x), inplace=True)
        x = self.pooling3(x)
        x = F.relu(self.convolution4_1(x), inplace=True)
        x = F.relu(self.convolution4_2(x), inplace=True)
        x = F.relu(self.convolution4_3(x), inplace=True)
        x = self.pooling4(x)
        x = F.relu(self.convolution5_1(x), inplace=True)
        x = F.relu(self.convolution5_2(x), inplace=True)
        x = F.relu(self.convolution5_3(x), inplace=True)
        return x

    def load_pretrain_model(self):
        state_dict = self.state_dict()
        param_name = list(state_dict.keys())
        # pretrain_model = models.vgg16(pretrained=True)#训练时
        pretrain_model = models.vgg16(pretrained=False)  # 推理时
        pretrained_state_dict = pretrain_model.state_dict()
        pretrained_param_name = list(pretrained_state_dict.keys())

        for i, param in enumerate(param_name):
            state_dict[param] = pretrained_state_dict[pretrained_param_name[i]]

        self.load_state_dict(state_dict)


class BLSTM(nn.Module):
    def __init__(self, channel, hidden_unit, bidirectional=True):
        super(BLSTM, self).__init__()
        self.lstm = nn.LSTM(channel, hidden_unit, bidirectional=bidirectional)

    def forward(self, x):
        """
        WARNING: The batch size of x must be 1.
        """
        x = x.transpose(1, 3)
        recurrent, _ = self.lstm(x[0])
        recurrent = recurrent[np.newaxis, :, :, :]
        recurrent = recurrent.transpose(1, 3)
        return recurrent


class CTPN_Model(nn.Module):
    def __init__(self):
        super(CTPN_Model, self).__init__()
        self.cnn = nn.Sequential()
        self.cnn.add_module('VGG_16', VGG_16())
        self.rnn = nn.Sequential()
        self.rnn.add_module('im2col', Im2col((3, 3), (1, 1), (1, 1)))
        self.rnn.add_module('blstm', BLSTM(3 * 3 * 512, 128))
        self.FC = nn.Conv2d(256, 512, 1)
        self.vertical_coordinate = nn.Conv2d(512, 4 * 10, 1)
        self.score = nn.Conv2d(512, 2 * 10, 1)

    def forward(self, x, val=False):
        x = self.cnn(x)
        x = self.rnn(x)
        x = self.FC(x)
        x = F.relu(x, inplace=True)
        vertical_pred = self.vertical_coordinate(x)
        score = self.score(x)
        return score, vertical_pred


# TensorboardX
dummy_input = torch.rand(4, 3, 512, 512)  # 假设输入4张3*512*512的图片
model = CTPN_Model()
with SummaryWriter(comment='CTPN_Model') as w:
    w.add_graph(model, (dummy_input,))

# hiddenlayer
model_1 = CTPN_Model()
dummy_input = torch.rand(4, 3, 512, 512)  # 假设输入4张3*512*512的图片
torch.onnx.export(model_1, dummy_input, "ctpn_model", verbose=True, opset_version=11)
hl_graph_1 = hl.build_graph(model_1, torch.zeros([4, 3, 512, 512]))
hl_graph_1.save(path='D:/Python/introduction to ai/CTPN_Model.png')
```

