# Task 5: AI Books  Stage 3

# Unsupervised Learning in Space and Time

任务描述：翻译《时空中的无监督学习》第一章中主要章节，包括无监督视觉学习概述、无监督学习的七个原则、无监督学习原则应用的实例。

## 第一章 无监督视觉学习：从像素到视觉

### 一、 无监督视觉学习概述

- 自然世界中的无监督视觉学习是理解智能、明白大脑如何工作、建立真正的智能系统的基础。

- 人类视觉的原理：大脑获取感知到的每一个像素，并赋予它们意义和价值；大脑复制所有这些像素，并将它们排列在不同层次的视觉空间和时间层上。

- 当前和未来无监督学习的发展趋势：

  1. 如今的计算机视觉研究主要专注于单个图像的识别和处理，很少有对视频进行识别和处理的算法

  2. 而如果我们需要进行无监督的学习，就更应该考虑现实世界中的物体是什么样的。现实中的物体在不同的时间会发生变化，物体的外观或位置会改变→物体的变化在时间和空间两个维度共存

  3. 物体在时间和空间上的变化又具有一致性和连贯性，并遵循一定的规则，这一特性在视频中得以体现，而这也是无监督视觉学习研究的问题，因此研究无监督视觉学习必须考虑以视频作为输入

### 二、 无监督学习的原则

**原则1： 物体是全局场景中的局部离群点，体积小，外观和运动与它们的大背景有所不同。**

- 物体通常比包含它们的场景更小
- 物体有着和其所在场景不同的外表，和场景形成对比
- 物体通常比场景更灵活，其运动方式更快、更复杂
- 图像中像素的视运动，是计算机视觉中的一个基本问题，也是任何机器人视觉系统的基本能力

**原则2：通常可以用高精度的算法（不一定有高召回率）来挑选出属于单个对象或类别的数据样本**。

- 虽然对象类别可能未知，但我们几乎可以确定样本确实属于同一类
- 当认识一个新物体时，我们会利用已有知识，先从中分离出我们能识别的部分，最后将各个部分组合起来，决定它属于哪个类别
- 几个已知的类在同一时空区域中的共现是新的类存在的指示，可以用其来训练新的分类器

**原则3：物体在时间和空间上表现出对称、相关和一致的特性。利用基于外观和运动的分组线索，我们可以获得高精度的正目标样本，这些线索很可能来自同一个对象或类别，称为高概率正特征。**

- 人类视觉中用来在视野中形成物体的分组线索，极有可能是高概率正特征（HPP），HPP极有可能将属于同一场景的部分聚集在一起
- 被聚集在一起的部分具有相似的外观和运动方式，而这种相似性不太可能是偶然发生的，因此这些部分很有可能属于同一个物体
- 基于外观和运动的分组线索可以为我们提供大量高精度的正面训练样本

**原则4：物体在其时空近邻形成明显的运动轨迹和外观模式。**

- 一个物体在时间和空间上具有连贯性和一致性
- 在研究无监督视觉学习时，我们可以将物体描述为时空中的点簇，这些点簇通过相似的运动轨迹和外观模式而紧密相连

**原则5：模型和图像间的匹配是十分罕见的。但匹配发生时，它通常是正确的。匹配可以基于几何或外观，当匹配发生时，会产生一个强大的集群。**

- 这一原则是无监督学习的核心
- 匹配是十分复杂的，基于形状的精细几何匹配，在运动模式中许多独立分类器输出或聚合的共现
- 匹配是应该开始学习新的物体和其他视觉类别的HPP的特征

**原则6：当几个独立的弱分类器一起触发时，表明存在一个更高层次的类，可以为这个类学习得到一个更强大的分类器。**

- 许多独立的分类器不太可能同时触发，除非它们在语义或抽象的更高层次上有相同的东西（可能是未知的类）
- 当上述情况发生时，可以通过将弱分类器组合来得到一个更强的分类器

**原则7： 为了改进或学习新的类，我们需要增加训练数据的数量和维度，以及提高分类器的能力和多样性。我们可以将现有分类器聚合起来作为新分类器的教师监督信号，以无监督的方式进行多代分类器的学习。**

- 新的类可能是与我们已知的类相比，有着更高语义级别的概念，也可能只是我们不知道的不同类别
- 学习任何种类的新类，起初只能使用已有的分类器
- 使用几代旧的分类器来协同工作，为新的更强大的分类器提供监督
- 一代又一代分类器可以进化，从只能识别非常简单和局部的对象，发展到对周围的视觉世界形成一种近乎完整、圆润、连贯的感觉，并最终形成一个普遍的无监督学习系统

### 三、 无监督学习原则的应用实例

#### 原则4的应用：视频中目标分割的无监督学习

**原则4：物体在其时空近邻形成明显的运动轨迹和外观模式。**

问题提出：哪些特征使一组像素在给定的序列中脱颖而出，成为一个单一的主要对象？是点运动轨迹的模式、共同的外观，还是与背景的对比？还是所有这些因素的结合？最好的结合方式是什么？

方法提出：在时间和空间中发现物体的方法，这一方法经广泛的实验验证表明，使用非常简单的运动和外观特征有可能发现物体在时空中的集群

方法描述：基于物体的双重视角，以互补的方式将时间和空间维度相结合。具体来说：（1）一个物体的同一点，在不同的时间点被不同的像素捕获，再通过长距离的运动链连接这些像素点，作为时间函数的空间轨迹；（2）占据不同空间位置的物体的不同点共享相似的运动和外观模式；（3）物体的运动和外观模式常常可以相互预测，并且这两者在时空中的特性保持一致，因此从运动中估计出来的东西也可以从外观中估计出来

方法结论：外观和运动可以相互提供监督信号，并协同工作

**视频中目标分割的无监督学习：**

分割：带有运动和外观约束的光谱聚类问题，被发现作为特征-运动矩阵的主要特征向量

原理：具有非负元素的对称矩阵的主特征向量自然地反映了其关联图的最主要、最强的聚类

#### 原则5的应用：谱图匹配

**原则5：模型和图像间的匹配是十分罕见的。但匹配发生时，它通常是正确的。匹配可以基于几何或外观，当匹配发生时，会产生一个强大的集群。**

**光谱图匹配算法**

算法用途：给出图形匹配问题的近似解

应用范围：可以用于多种应用，因为算法以最一般的形式处理图匹配问题，如整数二次规划，并且它不对一元和二阶项强加特定的数学形式。唯一约束：一元和成对的分数必须是非负的

关键：正确的匹配之间将有很高的二阶分数，而不正确的匹配之间不太可能有高分

算法原理：看作候选匹配图的加权邻接矩阵。每个候选匹配（或对应关系）$(i,a)$可以看作这个图中的一个节点，其包含了候选匹配之间局部外观一致性的信息。节点之间的链接可以包含关于候选匹配之间的成对几何信息保存得如何的信息。较大的节点对应较强的一元分数（在局部外观水平的一致性较好），较粗的边对应与更大的成对分数，反映了在二阶几何水平上更强的一致性。我们期望正确的匹配将形成一个强连通簇，这个簇可以通过分析匹配图的加权邻接矩阵$M$的主导特征向量来找到。特征向量的元素可以解释为每个候选匹配都是正确的的置信度，利用整数约束对特征向量进行二值化，最终得到图匹配问题的近似解。

> 图：矩阵$M$的结构，正确的匹配会在$M$中形成一个含有大量成对元素的强块，而错误匹配之间的成对分值大多为零。$M$的这个统计性质将反映在它的主特征向量上。

<img src="C:\Users\WJY\AppData\Roaming\Typora\typora-user-images\image-20201217121430415.png" alt="image-20201217121430415" style="zoom:50%;" />

算法过程：

1. 创建候选匹配图：构建候选匹配$ia$的矩阵$M$，该矩阵将来自模型的特征$i$与来自图像的特征$a$对应起来，使非对角元素$M_{ia;jb}$获取候选匹配$ia$和$jb$之间的一致程度：它们有效地测量了来自模型的对$(i, j)$的几何形状和外观与来自图像的对$(a, b)$的几何形状和外观的匹配程度。该矩阵应该有非负元素，其值随着候选匹配$ia$和$jb$之间匹配（一致性）质量的增加而增加。因此，每个候选匹配$ia$都成为候选匹配图中的一个节点。$M_{ia;jb}$的边上的值衡量候选匹配$ia$和$jb$之间的一致性。

2. 高效优化：用幂迭代算法计算$M$的主导特征向量$v$。在实践中，少数迭代(10-20次)就足够了。特征向量的大小将与候选匹配的数量相同，并且只有非负值。每个$v_{ia}$的值表示候选匹配属于匹配图中主要、最强聚类的程度。置信值是对匹配$ia$正确的可能性的度量。

3. 找到最终的离散解：最终的离散解以贪婪的方式快速得到：(1)我们从还没有被选中或淘汰的$ia$中选择$v_{ia}$值最高的匹配$ia^*$；（2）然后，我们舍弃剩余的候选匹配中所有与$ia^∗$冲突的匹配（可能具有相同的源或目标特征。然后我们回到第一步。

   这一过程一直持续到所有匹配图都被正确选择或丢弃。

#### 原则7的应用：教师-学生多代无监督分割学习

**原则7： 为了改进或学习新的类，我们需要增加训练数据的数量和维度，以及提高分类器的能力和多样性。我们可以将现有分类器聚合起来作为新分类器的教师监督信号，以无监督的方式进行多代分类器的学习。**

**教师-学生多代无监督分割学习**

系统组成：两条分支，教师分支和学生分支

​        教师分支：在视频或大型图像集合中执行无监督的对象发现

​        学生分支：从教师分支那里学习如何在单个图像中分割前景对象

算法性能关键：（1）存在一个无监督的选择模块，该模块能够拾取教师分支生成的高质量掩码，并将它们传递给下一代学生分支进行训练；（2）训练具有不同体系结构的多个学生，通过他们的多样性来帮助为下一次迭代训练培养更好的选择模块，在下一次迭代中与选择模块一起形成更强大的教师分支；（3）访问大量（可能是更复杂的）无标签数据，随着每一代变得更强大，这一步骤变得更加有用

算法过程：在无监督训练阶段，学生网络（模块A）从无监督的教师路径（模块B和模块C）一帧一帧地学习，以在单一图像中产生相似的对象掩模。模块B发现图像或视频中的对象，模块C模块B生产的足够好的掩模，将其传递给模块A进行训练。因此，学生分支试图为模块C选择的帧模仿模块B的输出。学生分支的输入只是单个图像——当前帧——而教师分支可以访问整个视频序列。模块A的能力取决于模块B的性能。然而，正如我们在实验中看到的，选择模块C的能力促成了一个事实，即新学生分支的性能将超越其最初的教师模块B。因此，在整篇文章中，我们把B称为初始的“教师”，把B和C一起称为完整的“教师路径”。

> 图 双学生-教师系统，用于无监督学习以分割图像中的前景对象

<img src="C:\Users\WJY\AppData\Roaming\Typora\typora-user-images\image-20201217125116202.png" alt="image-20201217125116202" style="zoom:67%;" />

算法步骤：

步骤1：沿教师路径在未标记的视频（或之后迭代得到的图像集合）上执行无监督的对象发现迭代

步骤2：自动过滤掉在上一步生产的劣质软掩模

步骤3：使用剩下的掩模作为监督信号，沿学生路径训练一个或多个学生网

步骤4：用当前一代的一个或几个学生网（一个新的模块B）作为新教师，并学习一个更强大的软掩模选择器（一个新的模块C），为下一次迭代作准备

步骤5：扩展未标记的视频或图像数据集，并返回到步骤1来训练下一代（注意：从第一次迭代开始，训练数据集也可以用未标记图像的集合来扩展，而不仅仅是视频）