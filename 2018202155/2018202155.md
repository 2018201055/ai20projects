# Task11 (NewsRec) Project I

GroupID:18   StudentID:2018202155

本项目主要是尝试用不同算法建立推荐系统模型，并建立评估模型，选出最优化算法模型，并作出进一步的改进。

我们目前已经实现了12/27个算法实例，其中我着重分析了以下6个算法：

1. Term Frequency - Inverse Document Frequency (TF-IDF)
2. LightFM/Hybrid Matrix Factorization
3. GeoIMC
4. xLearn/Factorization Machine (FM) & Field-Aware FM (FFM)
5. GRU4Rec
6. Short-term and Long-term preference Integrated Recommender (SLi-Rec)

 

## 搭建环境

1. 本地环境：安装带有3.6以上版本Python的Anaconda，用git将Recommerders仓库克隆到本地。然后创建并激活conda环境。

  

## 算法思路

**1. Term Frequency - Inverse Document Frequency (TF-IDF)**

用TF-IDF基于内容作推荐。该算法用到的是COVID-19 Open Research Dataset中license为cc0的数据，是文本类型的数据，数据量为258。

首先是数据预处理，将数据集中的原始数据转换为dataframe格式，选取cc0中的数据，并提取各文件里的完整文本内容。

然后文本分词，去除停用词，创建一个对象调用TfidfRecommende，训练模型，对每一个类型的参考文本返回与它相似度较高的前k个文本。其中，相似度的计算是基于TF-IDF算法，计算词频和逆文档频率，进而计算两篇文章之间的余弦相似值。

 

**2. LightFM/Hybrid Matrix Factorization**

推荐系统中会遇到冷启动问题（cold-start issue）也就是没有足够的历史数据，大致有3个类型：

1. 新平台，比如一个新网上购物平台，只有商品信息，没有用户、购买记录。

2. 新条目，比如新商品，缺乏访问次数，会导致推荐不准确，且缺少推荐，造成负反馈，导致流行偏见问题(popularity bias)

3. 新用户，缺乏访问或购买记录

为了解决这个问题，提出了组合协同过滤和内容推荐这两种推荐方法的混合推荐系统，其中之一是hybrid matrix factorisation模型，它组合了矩阵分解和LightFM包。

 

LightFM model:

U : 用户集

I : 物品集

每个用户有一系列用户特征
$$
f_u\subset F_U
$$
每个物品有一系列物品特征
$$
f_i\subset F_I
$$
该模型返回二值，评级会归一化为两组。对于显式评级，将用户物品对
$$
(u,i)\in U \times I
$$
分为正集合![img](file:////private/var/folders/d0/rhx4r2096y3744tt7dwn9njh0000gn/T/com.kingsoft.wpsoffice.mac/wps-danyuwang/ksohtml/wps1wo5we.jpg)和负集合![img](file:////private/var/folders/d0/rhx4r2096y3744tt7dwn9njh0000gn/T/com.kingsoft.wpsoffice.mac/wps-danyuwang/ksohtml/wpsv9xxKL.jpg)；对于隐性的反馈分为被观察的和不被观察的。

用户u和物品i的embedding为相应特征向量的和：
$$
q_u=\sum _{j\in f_u}e_j^U\\
p_i=\sum _{j\in f_i}e_j^I
$$
用户u和物品i的偏差为相应偏差向量的和：
$$
b_u=\sum _{j\in f_u}b_j^U\\
b_i=\sum _{j\in f_i}b_j^I
$$
 每个用户和物品表示为它特征向量的加权线性和。

预测用户u和物品i：
$$
r_{ui}=\sigma (q_u\cdot p_i+b_u+b_i)
$$
sigoid函数是进行归一化，以返回二值。

用随机梯度下降表示可能性，极大似然进行训模型拟合。可能性的表达式为：
$$
L=\prod _{(u,i)\in S^+}r_{ui}\times \prod_{(u,i)\in S^-}1-r_{ui}
$$



**3.  GeoIMC(Geometry Aware Inductive Matrix Completion)**

矩阵补全问题：有一个巨大的矩阵，人们只能观测到其中到部分元素，解决如何补全整个矩阵的问题。在推荐系统中，比如电影评分网站上，有很多用户（矩阵的行）给很多电影（矩阵的列）进行打分，但每个用户只会对很少一部分电影评分，那么矩阵中只有一部分值可被观测到，此时我们想预测用户对没有评分的电影的打分，也就是解决一个矩阵补全问题。

使用数据集MovieLens-100K，设
$$
X\in R^{m\times d_1} , Z\in R^{n\times d_2}
$$
分别为用户和电影的特征，
$$
U\in R^{m\times n}
$$
是部分观测到的评分矩阵。

GeoIMC将该矩阵建模为如下形式：
$$
M=XUBV^TZ^T
$$
其中
$$
U\in R^{d_1\times k},V\in R^{d_2\times k},B\in R^{k\times k}
$$
分别为正交矩阵、正交矩阵、对称正定矩阵。最优化问题通过Pymanopt解决。

 

 

**4. xLearn/Factorization Machine (FM) & Field-Aware FM (FFM)**

因子分解机，可处理高度稀疏的数据集，它不仅捕捉到输入的特征，而且**关注了特征与特征之间的相互关系** ，所以很强大。和其他传统算法比如SVM相比呈现出较好的泛化能力和表现。

最新的研究用深度学习方法延伸扩展了基本的FM算法，在几个应用实例中达到了显著的提升。

用户、物品、特征向量可表示为独热表达，此时传统的算法比如线性回归、SVM可能有以下问题：

1. 特征向量高度稀疏，因此，很难高效地优化参数拟合模型。

2. 特征的叉乘也会很稀疏，这样如果用它来刻画特征间的高阶交互，会降低模型的表现。

FM算法通过分解隐向量解决上述问题，它的大致思想是：
$$
y(x)=\omega_0+\sum _{i=1}^n \omega_ix_i+\sum_{i=1}^n\sum_{j=i+1}^n<v_i,v_j>x_ix_j
$$
其中x是输入的特征向量，y是待预测值，![img](file:////private/var/folders/d0/rhx4r2096y3744tt7dwn9njh0000gn/T/com.kingsoft.wpsoffice.mac/wps-danyuwang/ksohtml/wpsssJTR5.jpg)是模型参数中的一阶元素，![img](file:////private/var/folders/d0/rhx4r2096y3744tt7dwn9njh0000gn/T/com.kingsoft.wpsoffice.mac/wps-danyuwang/ksohtml/wpsKYqp6l.jpg)是二阶相互关系，它是两个隐向量的点积，定义为：
$$
<v_i,v_j> =\sum_{f=1}^kv_{i,f}\cdot v_{j,f}
$$
计算复杂度为O(kn)，这里高阶交互元素中使用分解的向量与使用固定参数相比，可以提高模型的泛化能力和表现。

 

FFM是FM的一个延伸。直觉上FM中特征共用隐向量来表示不同类别的信息可能并不能很好地泛化相关度，FFM解决了这一问题，它在不同组的特征中使用了不同的分解隐向量，“组”在FFM中表述为'field'。FFM中二阶交互定义为：
$$
\theta_{FFM}(wx)=\sum_{j_1=1}^n\sum_{j_2=j_1+1}^n<v_{j_1,f_2},v_{j_2,f_1}>x_{j_1}x_{j_2}
$$
时间复杂度提高到了O(k*n^2)，但是FFM中的隐向量只需要在field内计算，所以FFM的k值通常会比FM中的小很多。

在本实验中，使用xlearn进行实现，它是用C++实现的，带Python接口，在能较高效地计算且不损失模型的有效性。



**序列推荐(sequential recommendation)**

以下五个模型都采用了序列推荐(sequential recommendation)，通过对用户（user）行为序列，比如购买商品（item）的序列来建模，学到user 兴趣的变化，从而能够对用户在短期内的行为或是下一次的行为进行预测。

- Attentive Asynchronous Singular Value Decomposition (A2SVD)

- Convolutional Sequence Embedding Recommendation (Caser)

- GRU4Rec

- Next Item Recommendation (NextItNet)

- Short-term and Long-term preference Integrated Recommender (SLi-Rec)

 

**5. GRU4Rec**

使用循环神经网络(recurrent neural network)捕捉用户的长期和短期偏好，在该模型中，使用完整的session行为序列信息，以session为粒度并行mini-batch，极大地加快了RNN-based模型训练。



**6. Short-term and Long-term preference Integrated Recommender (SLi-Rec)**

本实验中用到的是基于深度学习的SLi_Rec模型，它捕捉了长期的和短期的用户偏好以更精准地进行推荐，它有几个关键性质：

1. 长期兴趣的建模采用了注意力机制的不对称SVD；

2. 通过修改LSTM中的门控机制，同时考虑到了时间和语义的不规则性

3. 使用注意力机制动态地将长期偏好和短期偏好融合在一起。

   

## 后期规划

算法的代码运行中还有一些问题需要调试，之后我们将继续把给出的算法逐一理解原理并实现，再提出改进方法。