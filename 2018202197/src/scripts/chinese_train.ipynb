{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.0 64-bit",
   "display_name": "Python 3.7.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100000\n['538405926243 买 二份 有没有 少点 呀', '亲亲 真的 不好意思 我们 已经 是 优惠价 了 呢 小本生意 请亲 谅解']\n['那 就 等 你们 处理 喽', '好 的 亲退 了']\n['那 我 不 喜欢', '颜色 的话 一般 茶刀 茶针 和 二合一 的话 都 是 红木 檀 和 黑木 檀 哦']\n['不是 免 运费', '本店 茶具 订单 满 99 包邮除 宁夏 青海 内蒙古 海南 新疆 西藏 满 39 包邮']\n['好吃 吗', '好吃 的']\n['为什么 迟迟 不 给 我 发货', '实在 抱歉 呢 由于 订单 量 大 您 的 订单 本来 安排 今天 发货 的 呢']\n['对 谢谢', '小店 尽快 给 您 发出 哦']\n['3 组送 什么', '拍 2 组送 2 包 湿巾 3 组 也 是 2 包']\n['那 我 马上 拍', '记得 勾选 优惠券 哦']\n['每 一样 都 要点 要 二百个', '单个 的话 价格 都 是 最低 了 哦 都 是 亏本 促销 的 只是 为了 前期 冲 销量 的 548881602868547107612966547393486364547259785739 这款 单买 可以 再 便宜 鲜肉 蜜枣 豆沙 最低 53 蛋黄 肉 粽 最低 63 元 哦']\n['百世', '好 的']\n['⊙ o ⊙ 哦 好 的', '优惠券 有效期 至 8 月 31 日 谢谢 客官 支持 小店 哦']\n['目前 我 只有 这些', '亲 只有 这些 齐全 的 才能 开']\n['可是 这个 没有 到 啊', '应该 这 两天 会到 的 这个 会 联系 下 快递']\n['单 怎么 下', '您 提交 以后 哪里 可以 修改 数量 的']\n['吃 起来 和 新鲜 的 有 很大 差别 嘛 保鲜', '吃 起来 也 很 松脆']\n['杭州 桐庐 几天 到', '一般 1 - 2 天']\n['别 给 我 像 发货 一样 的 慢', '不会 的 呢']\n['我 买 的 东西 发货 了 没 怎么 看不见 物流', '亲亲 实在 抱歉 仓库 那边 说 配货 的 时候 椒盐 味纸 皮 核桃 缺货 了 呢 新 的 一批 明天 才 到货 哦 到货 后 第一 时间 给 您 打包 哦 亲亲 不要 着急 哦']\n['嗯 呢 要 不到 不了 啊', '嗯 嗯 已经 给 您 修改 好 了 哦']\n"
     ]
    }
   ],
   "source": [
    "#数据预处理，拆成pair<question,answer>\n",
    "with open('../chinese_data/question_answer.txt',\"r\") as f:    #设置文件对象\n",
    "    data=f.readlines()\n",
    "    print(len(data))\n",
    "    after_deal=[]\n",
    "    for line in data:\n",
    "        line=line.strip(\"\\n\")\n",
    "        after_deal.append(line.split(\"\\t\"))\n",
    "        \n",
    "for line in after_deal[:20]:\n",
    "    print(line)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "counted words 21393\n"
     ]
    }
   ],
   "source": [
    "#构造词典\n",
    "voc = Voc('communicate')\n",
    "pairs = after_deal\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "print(\"counted words\", voc.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "keep_words 9399 / 21390 = 0.4394\n",
      "Trimmed from 100000 pairs to 88237, 0.8824 of total\n"
     ]
    }
   ],
   "source": [
    "#去除低频词\n",
    "MIN_COUNT = 3 \n",
    "voc.trim(MIN_COUNT)\n",
    "keep_pairs = []\n",
    "for pair in pairs:\n",
    "    input_sentence = pair[0]\n",
    "    output_sentence = pair[1]\n",
    "    keep_input = True\n",
    "    keep_output = True\n",
    "    for word in input_sentence.split(' '):\n",
    "        if word not in voc.word2index:\n",
    "            keep_input = False\n",
    "            break\n",
    "    for word in output_sentence.split(' '):\n",
    "        if word not in voc.word2index:\n",
    "            keep_output = False\n",
    "            break\n",
    "    if keep_input and keep_output:\n",
    "        keep_pairs.append(pair)\n",
    "\n",
    "print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input_variable: tensor([[ 204,  276,  255,   43,   43],\n        [ 593,   44,  460,    6,    2],\n        [ 255,  185,   28,  665,    0],\n        [ 276,   30, 1159,  519,    0],\n        [ 185,  242, 7828, 2283,    0],\n        [ 150,   81,   28,  144,    0],\n        [ 597,  270,  908,    2,    0],\n        [  30, 1131,  356,    0,    0],\n        [  22,  986, 3188,    0,    0],\n        [ 142,  347,    2,    0,    0],\n        [ 111,    2,    0,    0,    0],\n        [ 215,    0,    0,    0,    0],\n        [ 490,    0,    0,    0,    0],\n        [ 276,    0,    0,    0,    0],\n        [  16,    0,    0,    0,    0],\n        [   2,    0,    0,    0,    0]])\nlengths: tensor([16, 11, 10,  7,  2])\ntarget_variable: tensor([[ 204,  369,   27, 3504,  204],\n        [ 204,   16,   28,  366,  204],\n        [  27,   17,  136,   17,  136],\n        [  28,  593,    2,    2,    2],\n        [   2,   72,    0,    0,    0],\n        [   0,  436,    0,    0,    0],\n        [   0,   16,    0,    0,    0],\n        [   0,  180,    0,    0,    0],\n        [   0,  998,    0,    0,    0],\n        [   0,   65,    0,    0,    0],\n        [   0,   72,    0,    0,    0],\n        [   0,  346,    0,    0,    0],\n        [   0,   99,    0,    0,    0],\n        [   0,   72,    0,    0,    0],\n        [   0,  438,    0,    0,    0],\n        [   0,   72,    0,    0,    0],\n        [   0,  358,    0,    0,    0],\n        [   0, 2878,    0,    0,    0],\n        [   0,  142,    0,    0,    0],\n        [   0,  874,    0,    0,    0],\n        [   0,  150,    0,    0,    0],\n        [   0,   12,    0,    0,    0],\n        [   0,  339,    0,    0,    0],\n        [   0,   72,    0,    0,    0],\n        [   0,  360,    0,    0,    0],\n        [   0,  110,    0,    0,    0],\n        [   0,   72,    0,    0,    0],\n        [   0,  438,    0,    0,    0],\n        [   0,  110,    0,    0,    0],\n        [   0,   62,    0,    0,    0],\n        [   0,    2,    0,    0,    0]])\nmask: tensor([[ True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True],\n        [ True,  True,  True,  True,  True],\n        [ True,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False],\n        [False,  True, False, False, False]])\nmax_target_len: 31\n"
     ]
    }
   ],
   "source": [
    "#构造tensor矩阵\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}