{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "模型的定义，模型来源为下面的论文：\n",
    "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf\n",
    "'''\n",
    "#导入各种需要的库\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import regularizers #正则化\n",
    "from keras.layers import (LSTM, BatchNormalization, Dense, Dropout, Embedding,\n",
    "                          Input, Lambda, TimeDistributed) #各种搭模型的函数\n",
    "from keras.models import Model\n",
    "\n",
    "unit_size = 512\n",
    "\n",
    "def model(vocab_size, max_len, reg):\n",
    "\n",
    "    # 图像模型\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    X_img = Dropout(0.5)(inputs1)\n",
    "    X_img = Dense(unit_size, use_bias = False, \n",
    "                        kernel_regularizer=regularizers.l2(reg),\n",
    "                        name = 'dense_img')(X_img)\n",
    "    X_img = BatchNormalization(name='batch_normalization_img')(X_img)\n",
    "    X_img = Lambda(lambda x : K.expand_dims(x, axis=1))(X_img)\n",
    "\n",
    "    # 文本处理层\n",
    "    inputs2 = Input(shape=(max_len,))\n",
    "    X_text = Embedding(vocab_size, unit_size, mask_zero = True, name = 'emb_text')(inputs2)\n",
    "    X_text = Dropout(0.5)(X_text)\n",
    "\n",
    "    # Initial States\n",
    "    a0 = Input(shape=(unit_size,))\n",
    "    c0 = Input(shape=(unit_size,))\n",
    "\n",
    "    LSTMLayer = LSTM(unit_size, return_sequences = True, return_state = True, dropout=0.5, name = 'lstm')\n",
    "\n",
    "    # Take image embedding as the first input to LSTM\n",
    "    _, a, c = LSTMLayer(X_img, initial_state=[a0, c0])\n",
    "\n",
    "    A, _, _ = LSTMLayer(X_text, initial_state=[a, c])\n",
    "    output = TimeDistributed(Dense(vocab_size, activation='softmax',\n",
    "                                     kernel_regularizer = regularizers.l2(reg), \n",
    "                                     bias_regularizer = regularizers.l2(reg)), name = 'time_distributed_softmax')(A)\n",
    "\n",
    "    return Model(inputs=[inputs1, inputs2, a0, c0], outputs=output, name='NIC')\n",
    "\n",
    "\n",
    "def greedy_inference_model(vocab_size, max_len):\n",
    "    \n",
    "    EncoderDense = Dense(unit_size, use_bias=False, name = 'dense_img')\n",
    "    EmbeddingLayer = Embedding(vocab_size, unit_size, mask_zero = True, name = 'emb_text')\n",
    "    LSTMLayer = LSTM(unit_size, return_state = True, name = 'lstm')\n",
    "    SoftmaxLayer = Dense(vocab_size, activation='softmax', name = 'time_distributed_softmax')\n",
    "    BatchNormLayer = BatchNormalization(name='batch_normalization_img')\n",
    "\n",
    "    # Image embedding\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    X_img = EncoderDense(inputs1)\n",
    "    X_img = BatchNormLayer(X_img)\n",
    "    X_img = Lambda(lambda x : K.expand_dims(x, axis=1))(X_img)\n",
    "\n",
    "    # Text embedding\n",
    "    inputs2 = Input(shape=(1,))\n",
    "    X_text = EmbeddingLayer(inputs2)\n",
    "\n",
    "    # Initial States\n",
    "    a0 = Input(shape=(unit_size,))\n",
    "    c0 = Input(shape=(unit_size,))\n",
    "\n",
    "    a, _, c = LSTMLayer(X_img, initial_state=[a0, c0])\n",
    "\n",
    "    x = X_text\n",
    "\n",
    "    outputs = []\n",
    "    for i in range(max_len):\n",
    "        \n",
    "        a, _, c = LSTMLayer(x, initial_state=[a, c])\n",
    "        output = SoftmaxLayer(a)\n",
    "        outputs.append(output)\n",
    "        x = Lambda(lambda x : K.expand_dims(K.argmax(x)))(output)\n",
    "        x = EmbeddingLayer(x)\n",
    "\n",
    "    return Model(inputs=[inputs1, inputs2, a0, c0], outputs=outputs, name='NIC_greedy_inference_v2')\n",
    "\n",
    "\n",
    "def image_dense_lstm():\n",
    "\n",
    "    EncoderDense = Dense(unit_size, use_bias = False, name = 'dense_img')\n",
    "    BatchNormLayer = BatchNormalization(name = 'batch_normalization_img')\n",
    "    LSTMLayer = LSTM(unit_size, return_state = True, name = 'lstm')\n",
    "\n",
    "    inputs = Input(shape=(2048,))\n",
    "    X_img = EncoderDense(inputs)\n",
    "    X_img = BatchNormLayer(X_img)\n",
    "    X_img = Lambda(lambda x : K.expand_dims(x, axis=1))(X_img)\n",
    "\n",
    "    a0 = Input(shape=(unit_size,))\n",
    "    c0 = Input(shape=(unit_size,))\n",
    "\n",
    "    a, _, c = LSTMLayer(X_img, initial_state=[a0, c0])\n",
    "\n",
    "    return Model(inputs=[inputs, a0, c0], outputs=[a, c])\n",
    "\n",
    "\n",
    "def text_emb_lstm(vocab_size):\n",
    "\n",
    "    EmbeddingLayer = Embedding(vocab_size, unit_size, mask_zero = True, name='emb_text')\n",
    "    LSTMLayer = LSTM(unit_size, return_state = True, name='lstm')\n",
    "    SoftmaxLayer = Dense(vocab_size, activation='softmax', name='time_distributed_softmax')\n",
    "\n",
    "    a0 = Input(shape=(unit_size,))\n",
    "    c0 = Input(shape=(unit_size,))\n",
    "    cur_word = Input(shape=(1,))\n",
    "\n",
    "    X_text = EmbeddingLayer(cur_word)\n",
    "    a, _, c = LSTMLayer(X_text, initial_state=[a0, c0])\n",
    "    output = SoftmaxLayer(a)\n",
    "\n",
    "    return Model(inputs=[a0, cur_word, c0], outputs=[output, a, c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "filckr8k 图像数据的预处理\n",
    "'''\n",
    "import numpy as np \n",
    "import os\n",
    "from pickle import dump, load\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3 #这里使用的是keras内置的inception_v3实现feature extraction\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def load_images_as_arrays(directory):\n",
    "    #加载图像路径\n",
    "    img_array_dict = {}\n",
    "    for img_file in os.listdir(directory):\n",
    "        \n",
    "        img_path = directory + '/' + img_file\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        x = np.array(img)\n",
    "\n",
    "        img_array_dict[os.path.splitext(img_file)[0]] = x\n",
    "    \n",
    "    return img_array_dict\n",
    "\n",
    "\n",
    "def extract_features(directory):\n",
    "    #实现extra features\n",
    "    base_model = InceptionV3(weights='imagenet') #直接使用在imagenet上训练好的inceptionV3\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)\n",
    "\n",
    "    img_id = []\n",
    "    img_matrices = []\n",
    "    for img_file in os.listdir(directory):\n",
    "        \n",
    "        img_path = directory + '/' + img_file\n",
    "        img = image.load_img(img_path, target_size=(299, 299))\n",
    "        #x = image.img_to_array(img)\n",
    "        #x = preprocess_input(x)\n",
    "        x = np.array(img.resize((224,224),resample=Image.BILINEAR))/255\n",
    "\n",
    "        img_id.append(os.path.splitext(img_file)[0])\n",
    "        img_matrices.append(x)\n",
    "    \n",
    "    img_matrices = np.array(img_matrices)\n",
    "    assert(len(img_matrices.shape)==4)\n",
    "\n",
    "    img_features = model.predict(img_matrices, verbose=1)\n",
    "\n",
    "    return {'ids':img_id, 'features':img_features}\n",
    "\n",
    "\n",
    "def extract_feature_from_image(file_dir):\n",
    "    #通过model.predict提取图片特征\n",
    "    img = image.load_img(file_dir, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    #base_model = InceptionV3(weights='imagenet')\n",
    "    base_model = VGG16(include_top=False,weights='imagenet')\n",
    "    base_model.trainable=False\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)\n",
    "\n",
    "    return model.predict(x)\n",
    "\n",
    "\n",
    "def load_features(dict_dir, dataset_dir, repeat_times = 1):\n",
    "\n",
    "    assert(repeat_times >= 1)\n",
    "    \n",
    "    img_ids = []\n",
    "    with open(dataset_dir, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            img_ids.append(os.path.splitext(line)[0])\n",
    "    \n",
    "    features_dict = load(open(dict_dir, 'rb'))\n",
    "    dataset_features = []\n",
    "    for img_id in img_ids:\n",
    "        fidx = features_dict['ids'].index(img_id)\n",
    "        dataset_features.append(np.vstack([features_dict['features'][fidx, :]]*repeat_times))\n",
    "\n",
    "    dataset_features = np.vstack(dataset_features)\n",
    "\n",
    "    return dataset_features\n",
    "\n",
    "\n",
    "image_directory = './datasets/Flickr8k_Dataset'\n",
    "features_dict = extract_features(image_directory)\n",
    "\n",
    "dump(features_dict, open('./datasets/features_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "filckr8k 文本描述数据预处理\n",
    "主要是构建tokenizer\n",
    "'''\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def load_token_text(token_dir):\n",
    "    \n",
    "    sents_dict = {}\n",
    "    with open(token_dir, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            words = line.strip('\\n').split()\n",
    "            img_id = words[0].split('.')[0]\n",
    "            sent = ' '.join(words[1:])\n",
    "\n",
    "            if img_id in sents_dict.keys():\n",
    "                sents_dict[img_id].append(sent)\n",
    "            else:\n",
    "                sents_dict[img_id] = [sent]\n",
    "            \n",
    "    return sents_dict\n",
    "\n",
    "\n",
    "def load_dataset_token(dataset_dir, token_dir, start_end = True):\n",
    "    \n",
    "    all_sents = load_token_text(token_dir)\n",
    "\n",
    "    img_ids = []\n",
    "    with open(dataset_dir, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            img_ids.append(os.path.splitext(line)[0])\n",
    "\n",
    "    sent_list = []\n",
    "    for id in img_ids:\n",
    "        for sent in all_sents[id]:\n",
    "            sent_ = sent\n",
    "            if start_end:\n",
    "                sent_ = 'startseq ' + sent_ + ' endseq'\n",
    "\n",
    "            sent_list.append(sent_)\n",
    "    \n",
    "    return sent_list\n",
    "\n",
    "\n",
    "def create_tokenizer(dataset_dir, token_dir, start_end = True, use_all = False):\n",
    "\n",
    "    num_words = None\n",
    "\n",
    "    sent_list = load_dataset_token(dataset_dir, token_dir, start_end)\n",
    "\n",
    "    if use_all:\n",
    "        tokenizer = Tokenizer()\n",
    "    else:\n",
    "        if num_words:\n",
    "            tokenizer = Tokenizer(num_words)\n",
    "        else:\n",
    "            tokenizer = Tokenizer()\n",
    "\n",
    "    tokenizer.fit_on_texts(sent_list)\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def clean_test_sentences(tokenizer, sents_list):\n",
    "\n",
    "    cleaned_sents_list= []\n",
    "    for sents in sents_list:\n",
    "        sequences = tokenizer.texts_to_sequences(sents)\n",
    "        cleaned_sents_list.append(tokenizer.sequences_to_texts(sequences))\n",
    "    \n",
    "    return cleaned_sents_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "定义BLEU的评价函数 \n",
    "\n",
    "'''\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
    "\n",
    "\n",
    "def load_filckr8k_features(dict_dir, dataset_dir):\n",
    "    \n",
    "    '''\n",
    "    加载已经预先提取出的图像特征\n",
    "    '''\n",
    "    \n",
    "    img_ids = []\n",
    "    with open(dataset_dir, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            img_ids.append(os.path.splitext(line)[0])\n",
    "\n",
    "    features = load_features(dict_dir, dataset_dir, repeat_times = 1)\n",
    "\n",
    "    return img_ids, features\n",
    "\n",
    "\n",
    "def decoder(inf_model, tokenizer, features, post_process = True):\n",
    "\n",
    "    '''\n",
    "    采用greedy search的算法\n",
    "    '''\n",
    "\n",
    "    assert(features.shape[0]>0 and features.shape[1] == 2048)\n",
    "\n",
    "    N = features.shape[0]\n",
    "\n",
    "    startseq = np.repeat([tokenizer.word_index['startseq']], N)\n",
    "    a0 = np.zeros([N, unit_size])\n",
    "    c0 = np.zeros([N, unit_size])\n",
    "\n",
    "    # 注意：输出维度为: [32, N, 7378]\n",
    "    y_preds = np.array(inf_model.predict([features, startseq, a0, c0], verbose = 1))\n",
    "\n",
    "    # 注意：输出维度为: [N, 32, 7378]\n",
    "    y_preds = np.transpose(y_preds, axes = [1,0,2])\n",
    "    \n",
    "    sequences = np.argmax(y_preds, axis = -1)\n",
    "    sents = tokenizer.sequences_to_texts(sequences)\n",
    "\n",
    "    if post_process:\n",
    "        # post processing: 'endseq'\n",
    "        sents_pp = []\n",
    "        for sent in sents:\n",
    "            if 'endseq' in sent.split():\n",
    "                words = sent.split()\n",
    "                sents_pp.append(' '.join(words[:words.index('endseq')]))\n",
    "            else:\n",
    "                sents_pp.append(sent)\n",
    "        sents = sents_pp\n",
    "\n",
    "    return sents\n",
    "\n",
    "\n",
    "def beam_search(decoder_model, a0 , c0, tokenizer, beam_width, max_len, alpha = 0.7):\n",
    "\n",
    "    '''\n",
    "    采用beam_search的算法\n",
    "    '''\n",
    "\n",
    "    assert(a0.shape == (1, unit_size) and c0.shape == (1, unit_size) and isinstance(beam_width, int) and\n",
    "             beam_width > 0 and max_len > 0)\n",
    "\n",
    "    start_word = np.array([tokenizer.word_index['startseq']])\n",
    "\n",
    "    output, a, c = decoder_model.predict([a0, start_word, c0], verbose=0)\n",
    "\n",
    "    assert(len(output.shape)==2 and beam_width<=output.shape[1])\n",
    "    \n",
    "    seeds = np.argpartition(-output, beam_width, axis=-1)[0, :beam_width]\n",
    "    start_words = np.array(seeds)\n",
    "    next_activates = np.repeat(a, beam_width, axis = 0)\n",
    "    next_cells = np.repeat(c, beam_width, axis = 0)\n",
    "\n",
    "    scores = [math.log(output[0, i]) for i in seeds]\n",
    "    routes = [[i] for i in seeds]\n",
    "    res = {'scores':[], 'routes':[]}\n",
    "\n",
    "    for i in range(max_len-1):\n",
    "\n",
    "        outputs, activations, cells = decoder_model.predict([next_activates, start_words, next_cells], \n",
    "                                                            verbose=0)\n",
    "\n",
    "        candidates = np.argpartition(-outputs, beam_width, axis=-1)[:,:beam_width]\n",
    "        candidates = [(r, c) for r in range(candidates.shape[0]) for c in candidates[r,:]]\n",
    "        candidates_scores = np.array([scores[r] + math.log(outputs[r, c]) for r, c in candidates])\n",
    "        if beam_width < len(candidates):\n",
    "            choosen_candidates = np.argpartition(-candidates_scores, beam_width)[:beam_width]\n",
    "        else:\n",
    "            choosen_candidates = np.arange(0, len(candidates))\n",
    "\n",
    "        start_words = []\n",
    "        next_activates = []\n",
    "        next_cells = []\n",
    "        updated_scores = []\n",
    "        updated_routes = []\n",
    "        for idx in choosen_candidates:\n",
    "            r, c = candidates[idx]\n",
    "            if c == tokenizer.word_index['endseq']:\n",
    "                res['routes'].append(routes[r])\n",
    "                \n",
    "                if i != 0:\n",
    "                    res['scores'].append(1/len(routes[r])**alpha * candidates_scores[idx])\n",
    "                else:\n",
    "                    res['scores'].append(-math.inf)\n",
    "                \n",
    "                beam_width -= 1\n",
    "            else:\n",
    "                start_words.append(c)\n",
    "                next_activates.append(activations[r, :])\n",
    "                next_cells.append(cells[r, :])\n",
    "\n",
    "                updated_scores.append(candidates_scores[idx])\n",
    "                updated_routes.append(routes[r]+[c])\n",
    "\n",
    "        start_words = np.array(start_words)\n",
    "        next_activates = np.array(next_activates)\n",
    "        next_cells = np.array(next_cells)\n",
    "        scores = updated_scores\n",
    "        routes = updated_routes\n",
    "\n",
    "        if beam_width <= 0:\n",
    "            break\n",
    "\n",
    "    res['scores'] += [1/len(routes[i])**alpha * scores[i] for i in range(len(scores))]\n",
    "    res['routes'] += routes\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def bleu_evaluation_greedy(model_dir, tokenizer, test_references, test_features, max_len):\n",
    "    #greadysearch下的BLEU评分\n",
    "    vocab_size = tokenizer.num_words or (len(tokenizer.word_index)+1)\n",
    "\n",
    "    # prepare inference model\n",
    "    NIC_inference = greedy_inference_model(vocab_size, max_len)\n",
    "    NIC_inference.load_weights(model_dir, by_name = True, skip_mismatch=True)\n",
    "\n",
    "    test_candidates = decoder(NIC_inference, tokenizer, test_features, True)\n",
    "\n",
    "    assert(len(test_references) == len(test_candidates))\n",
    "\n",
    "    scores = {'BLEU-1':[], 'BLEU-2':[], 'BLEU-3':[], 'BLEU-4':[]}\n",
    "    for i in range(len(test_candidates)):\n",
    "        references = [r.lower().split() for r in test_references[i]]\n",
    "        candidate = test_candidates[i].split()\n",
    "\n",
    "        scores['BLEU-1'].append(sentence_bleu(references, candidate, weights=(1.0, 0, 0, 0), \n",
    "                                smoothing_function=SmoothingFunction().method1))\n",
    "        scores['BLEU-2'].append(sentence_bleu(references, candidate, weights=(0.5, 0.5, 0, 0), \n",
    "                                smoothing_function=SmoothingFunction().method1))\n",
    "        scores['BLEU-3'].append(sentence_bleu(references, candidate, weights=(0.333, 0.333, 0.333, 0), \n",
    "                                smoothing_function=SmoothingFunction().method1))\n",
    "        scores['BLEU-4'].append(sentence_bleu(references, candidate, weights=(0.25, 0.25, 0.25, 0.25), \n",
    "                                smoothing_function=SmoothingFunction().method1))\n",
    "\n",
    "    scores['BLEU-1'] = np.average(scores['BLEU-1'])\n",
    "    scores['BLEU-2'] = np.average(scores['BLEU-2'])\n",
    "    scores['BLEU-3'] = np.average(scores['BLEU-3'])\n",
    "    scores['BLEU-4'] = np.average(scores['BLEU-4'])\n",
    "\n",
    "    print('BLEU-1', scores['BLEU-1'])\n",
    "    print('BLEU-2', scores['BLEU-2'])\n",
    "    print('BLEU-3', scores['BLEU-3'])\n",
    "    print('BLEU-4', scores['BLEU-4'])\n",
    "\n",
    "    return test_candidates\n",
    "\n",
    "\n",
    "def bleu_evaluation_beam_search(model_dir, tokenizer, test_references, test_features, max_len, beam_width, alpha):\n",
    "    #计算beam_search算法下的评分\n",
    "    vocab_size = tokenizer.num_words or (len(tokenizer.word_index)+1)\n",
    "\n",
    "    # prepare inference model\n",
    "    NIC_text_emb_lstm = text_emb_lstm(vocab_size)\n",
    "    NIC_text_emb_lstm.load_weights(model_dir, by_name = True, skip_mismatch=True)\n",
    "    NIC_image_dense_lstm = image_dense_lstm()\n",
    "    NIC_image_dense_lstm.load_weights(model_dir, by_name = True, skip_mismatch=True)\n",
    "\n",
    "    feature_size = test_features.shape[0]\n",
    "    a0, c0 = NIC_image_dense_lstm.predict([test_features, np.zeros([feature_size, unit_size]), np.zeros([feature_size, unit_size])])\n",
    "\n",
    "    # generate candidate sentences\n",
    "    test_candidates = []\n",
    "    for i in range(feature_size):\n",
    "        res = beam_search(NIC_text_emb_lstm, a0[i, :].reshape(1,-1), c0[i, :].reshape(1,-1), tokenizer, beam_width, max_len, alpha)\n",
    "        best_idx = np.argmax(res['scores'])\n",
    "        test_candidates.append(tokenizer.sequences_to_texts([res['routes'][best_idx]])[0])\n",
    "\n",
    "    assert(len(test_references) == len(test_candidates))\n",
    "\n",
    "    scores = {'BLEU-1':[], 'BLEU-2':[], 'BLEU-3':[], 'BLEU-4':[]}\n",
    "    for i in range(len(test_candidates)):\n",
    "        references = [r.split() for r in test_references[i]]\n",
    "        candidate = test_candidates[i].split()\n",
    "        scores['BLEU-1'].append(sentence_bleu(references, candidate, weights=(1.0, 0, 0, 0), smoothing_function=SmoothingFunction().method1))\n",
    "        scores['BLEU-2'].append(sentence_bleu(references, candidate, weights=(0.5, 0.5, 0, 0), smoothing_function=SmoothingFunction().method1))\n",
    "        scores['BLEU-3'].append(sentence_bleu(references, candidate, weights=(0.333, 0.333, 0.333, 0), smoothing_function=SmoothingFunction().method1))\n",
    "        scores['BLEU-4'].append(sentence_bleu(references, candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=SmoothingFunction().method1))\n",
    "\n",
    "    print('BLEU-1', np.average(scores['BLEU-1']))\n",
    "    print('BLEU-2', np.average(scores['BLEU-2']))\n",
    "    print('BLEU-3', np.average(scores['BLEU-3']))\n",
    "    print('BLEU-4', np.average(scores['BLEU-4']))\n",
    "\n",
    "    return test_candidates\n",
    "\n",
    "\n",
    "def evaluate_one(model_dir, method='b', beam_width = 5, alpha = 0.7):\n",
    "    '''\n",
    "    To evaluate one model by BLEU in a directory and return relevant information\n",
    "    inputs:\n",
    "    b - beam_search\n",
    "        beam_width and alpha only effective when method = 'b'\n",
    "    g - gready search\n",
    "    outputs:\n",
    "    1. test_ids: relevant image file names\n",
    "    2: test_references: relevant ground truth sentences\n",
    "    3: candidates: sentences generated by NIC geedy or beam search inference model\n",
    "    (the order is the same)\n",
    "    examples:\n",
    "    model_dir = './model-params/xxxx.h5' # a model weight file address\n",
    "    img_ids, refs, cands = evaluate_all(model_dir, method='b', beam_width = 5, alpha = 0.7)\n",
    "    '''\n",
    "\n",
    "    dict_dir = './datasets/features_dict.pkl'\n",
    "    train_dir = './datasets/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "    test_dir = './datasets/Flickr8k_text/Flickr_8k.testImages.txt'\n",
    "    token_dir = './datasets/Flickr8k_text/Flickr8k.token.txt'\n",
    "\n",
    "    max_len = 24\n",
    "\n",
    "    tokenizer = create_tokenizer(train_dir, token_dir)\n",
    "    filter_tokenizer = create_tokenizer(test_dir, token_dir, use_all=True)\n",
    "\n",
    "    test_ids, test_features = load_filckr8k_features(dict_dir, test_dir)\n",
    "    all_sents = load_token_text(token_dir)\n",
    "    test_references = [all_sents[id] for id in test_ids]\n",
    "\n",
    "    test_references = clean_test_sentences(filter_tokenizer, test_references)\n",
    "\n",
    "    if method == 'g':\n",
    "        candidates = bleu_evaluation_greedy(model_dir, tokenizer, test_references, test_features, max_len)\n",
    "    elif method == 'b':\n",
    "        candidates = bleu_evaluation_beam_search(model_dir, tokenizer, test_references, test_features, max_len, beam_width, alpha)\n",
    "    \n",
    "    return test_ids, test_references, candidates\n",
    "\n",
    "\n",
    "def evaluate_all(models_dir, method='b', beam_width = 5, alpha = 0.7):\n",
    "    '''\n",
    "    To evaluate all models by BLEU in a directory and return relevant information\n",
    "    inputs:\n",
    "    b - beam_search\n",
    "        beam_width and alpha only effective when method = 'b'\n",
    "    g - gready search\n",
    "    outputs:\n",
    "    1. test_ids: relevant image file names\n",
    "    2. model_ids: relevant model file names\n",
    "    3: test_references: relevant ground truth sentences\n",
    "    4: candidates_list: sentences generated by NIC geedy or beam search inference model\n",
    "    (the order is the same)\n",
    "    examples:\n",
    "    models_dir = './model-params' # the directory with a lot of same model structure weights\n",
    "    img_ids, mid, refs, cands_list = evaluate_all(models_dir, method='b', beam_width = 5, alpha = 0.7)\n",
    "    '''\n",
    "\n",
    "    dict_dir = './datasets/features_dict.pkl'\n",
    "    train_dir = './datasets/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "    test_dir = './datasets/Flickr8k_text/Flickr_8k.testImages.txt'\n",
    "    token_dir = './datasets/Flickr8k_text/Flickr8k.token.txt'\n",
    "\n",
    "    max_len = 24\n",
    "\n",
    "    tokenizer = create_tokenizer(train_dir, token_dir)\n",
    "    filter_tokenizer = create_tokenizer(test_dir, token_dir, use_all=True)\n",
    "\n",
    "    test_ids, test_features = load_filckr8k_features(dict_dir, test_dir)\n",
    "    all_sents = load_token_text(token_dir)\n",
    "    test_references = [all_sents[id] for id in test_ids]\n",
    "    \n",
    "    test_references = clean_test_sentences(filter_tokenizer, test_references)\n",
    "\n",
    "    candidates_list = []\n",
    "    model_ids = []\n",
    "    for model_file in os.listdir(models_dir):\n",
    "        print('----------', model_file)\n",
    "        model_ids.append(model_file)\n",
    "        model_path = models_dir + '/' + model_file\n",
    "        if method == 'g':\n",
    "            candidates = bleu_evaluation_greedy(model_path, tokenizer, test_references, test_features, max_len)\n",
    "        elif method == 'b':\n",
    "            candidates = bleu_evaluation_beam_search(model_path, tokenizer, test_references, test_features, max_len, beam_width, alpha)\n",
    "        candidates_list.append(candidates)\n",
    "    \n",
    "    return test_ids, model_ids, test_references, candidates_list\n",
    "\n",
    "\n",
    "model_dir = './model-params-his/current_best.h5'\n",
    "img_ids, test_references, candidates = evaluate_one(model_dir, method='b', beam_width = 5, alpha = 0.6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "主要是为了用tensorboard的模块，可忽略\n",
    "'''\n",
    "\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "class TensorBoardCaption(Callback):\n",
    "\n",
    "    def __init__(self, tokenizer, \n",
    "                       vocab_size,\n",
    "                       max_len, \n",
    "                       beam_width = 5, \n",
    "                       alpha = 0.7,\n",
    "                       log_dir = './logs/captions', \n",
    "                       feed_pics_dir = './eval', \n",
    "                       model_params_dir = './model-params'):\n",
    "        super(TensorBoardCaption, self).__init__()\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        self.beam_width = beam_width\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "        self.current_model_weigths_dir = model_params_dir + '/tensor_board_caption_weigths.h5'\n",
    "        self.images = load_images_as_arrays(feed_pics_dir)\n",
    "\n",
    "        self.image_features = extract_features(feed_pics_dir)\n",
    "\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "        self.font_tyle = ImageFont.truetype('c:/windows/fonts/Arial.ttf', size = 20)\n",
    "        self.font_color = (116, 0, 0) # or Red (255, 0, 0)\n",
    "\n",
    "        print('Tensor board caption is ready ...')\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        self.model.save_weights(self.current_model_weigths_dir)\n",
    "\n",
    "        NIC_text_emb_lstm = text_emb_lstm(self.vocab_size)\n",
    "        NIC_text_emb_lstm.load_weights(self.current_model_weigths_dir, by_name = True, skip_mismatch=True)\n",
    "        NIC_image_dense_lstm = image_dense_lstm()\n",
    "        NIC_image_dense_lstm.load_weights(self.current_model_weigths_dir, by_name = True, skip_mismatch=True)\n",
    "\n",
    "        summary_str = []\n",
    "        for id, image_array in self.images.items():\n",
    "            fidx = self.image_features['ids'].index(id)\n",
    "            a0, c0 = NIC_image_dense_lstm.predict([self.image_features['features'][fidx, :].reshape(1, -1), np.zeros([1, unit_size]), np.zeros([1, unit_size])])\n",
    "            res = beam_search(NIC_text_emb_lstm, a0.reshape(1,-1), c0.reshape(1,-1), self.tokenizer, self.beam_width, self.max_len, self.alpha)\n",
    "            best_idx = np.argmax(res['scores'])\n",
    "            caption = self.tokenizer.sequences_to_texts([res['routes'][best_idx]])[0]\n",
    "\n",
    "            summary_str.append(tf.Summary.Value(tag= id, image= self.make_image(image_array, caption)))\n",
    "\n",
    "        self.writer.add_summary(tf.Summary(value = summary_str), epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()\n",
    "\n",
    "\n",
    "    def make_image(self, tensor, caption):\n",
    "        \"\"\"\n",
    "        Convert an numpy representation image to Image protobuf and add caption.\n",
    "        modified from https://github.com/lanpa/tensorboard-pytorch/\n",
    "        \"\"\"\n",
    "        height, width, channel = tensor.shape\n",
    "        image = Image.fromarray(tensor)\n",
    "        \n",
    "        ImageDraw.Draw(image).multiline_text(\n",
    "            xy = (0, 0),  # Coordinates\n",
    "            text = self.__caption_format(caption),  # Text\n",
    "            fill = self.font_color,\n",
    "            font = self.font_tyle\n",
    "        )\n",
    "        output = io.BytesIO()\n",
    "        image.save(output, format='PNG')\n",
    "        image_string = output.getvalue()\n",
    "        output.close()\n",
    "        return tf.Summary.Image(height=height,\n",
    "                                width=width,\n",
    "                                colorspace=channel,\n",
    "                                encoded_image_string=image_string)\n",
    "\n",
    "\n",
    "    def __caption_format(self, caption, max_length = 7):\n",
    "\n",
    "        words = caption.split(' ')\n",
    "        multiline_words = []\n",
    "        for i in range(len(words)):\n",
    "            multiline_words.append(words[i])\n",
    "            if i!= 0 and i % max_length == 0:\n",
    "                multiline_words[-1] = '\\n' + multiline_words[-1]\n",
    "        \n",
    "        return ' '.join(multiline_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\"\"\"\n",
    "生成每一个batch可直接用于训练的数据\n",
    "\"\"\"\n",
    "\n",
    "def batch_generator(batch_size, max_len, tokenizer, dict_dir, dataset_dir, token_dir):\n",
    "\n",
    "    vocab_size = tokenizer.num_words or (len(tokenizer.word_index)+1)\n",
    "\n",
    "    img_features = load_features(dict_dir, dataset_dir, 5)\n",
    "    raw_sentences = load_dataset_token(dataset_dir, token_dir, True)\n",
    "\n",
    "    N = img_features.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        for i in range(0, N, batch_size):\n",
    "\n",
    "            sequences = tokenizer.texts_to_sequences(raw_sentences[i:i+batch_size])\n",
    "                \n",
    "            X_text = []\n",
    "            Y_text = []\n",
    "            for seq in sequences:\n",
    "                if len(seq) > max_len:\n",
    "                    X_text.append(seq[:max_len])\n",
    "                    Y_text.append(seq[1:max_len+1])\n",
    "                else:\n",
    "                    X_text.append(seq[:len(seq)-1] + [0]*(max_len-len(seq)+1))\n",
    "                    Y_text.append(seq[1:] + [0]*(max_len-len(seq)+1))\n",
    "\n",
    "            X_text_mat = np.array(X_text)\n",
    "            Y_text_mat = to_categorical(Y_text, vocab_size)\n",
    "\n",
    "            yield ([img_features[i:i+batch_size, :], X_text_mat, np.zeros([X_text_mat.shape[0], unit_size]), np.zeros([X_text_mat.shape[0], unit_size])], \n",
    "                    Y_text_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "训练模型的部分\n",
    "'''\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "def training(dirs_dict, lr, decay, reg, batch_size, epochs, max_len, initial_epoch, previous_model = None):\n",
    "\n",
    "    dict_dir = dirs_dict['dict_dir']\n",
    "    token_dir = dirs_dict['token_dir']\n",
    "    train_dir = dirs_dict['train_dir']\n",
    "    dev_dir = dirs_dict['dev_dir']\n",
    "    params_dir = dirs_dict['params_dir']\n",
    "\n",
    "    #使用前面构造的tokenizer创建词汇表\n",
    "    tokenizer = create_tokenizer(train_dir, token_dir, start_end = True)\n",
    "    \n",
    "    generator_train = batch_generator(batch_size, max_len, tokenizer, dict_dir, train_dir, token_dir)\n",
    "    generator_dev = batch_generator(50, max_len, tokenizer, dict_dir, dev_dir, token_dir)\n",
    "\n",
    "    vocab_size = tokenizer.num_words or (len(tokenizer.word_index)+1)\n",
    "\n",
    "    NIC_model = model(vocab_size, max_len, reg)\n",
    "\n",
    "    if not previous_model:\n",
    "        NIC_model.summary()\n",
    "        plot_model(NIC_model, to_file='./model.png',show_shapes=True)\n",
    "    else:\n",
    "        NIC_model.load_weights(previous_model, by_name = True, skip_mismatch=True)\n",
    "\n",
    "    # 定义callback，方便保存best model\n",
    "    file_path = params_dir + '/model-ep{epoch:03d}-loss{loss:.4f}-val_loss{val_loss:.4f}.h5'\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_weights_only = True, period=1)\n",
    "    tbc = TensorBoardCaption(tokenizer, vocab_size, max_len, log_dir = './logs', \n",
    "                            feed_pics_dir = './put-your-image-here',\n",
    "                            model_params_dir = params_dir)\n",
    "\n",
    "\n",
    "    # 编译模型\n",
    "    NIC_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr = lr, decay=decay), metrics=['accuracy'])\n",
    "\n",
    "    # 模型训练\n",
    "    NIC_model.fit_generator(generator_train, steps_per_epoch=30000//batch_size, epochs=epochs, verbose=2, \n",
    "                            callbacks=[checkpoint, tbc],\n",
    "                            validation_data = generator_dev, validation_steps = 100, initial_epoch = initial_epoch)\n",
    "\n",
    "\n",
    "\n",
    "dict_dir = './datasets/features_dict.pkl'\n",
    "train_dir = './datasets/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "dev_dir = './datasets/Flickr8k_text/Flickr_8k.devImages.txt'\n",
    "token_dir = './datasets/Flickr8k_text/Flickr8k.token.txt'\n",
    "# 存放训练好的模型的路径\n",
    "params_dir = './model-params'\n",
    "\n",
    "dirs_dict={'dict_dir':dict_dir, 'train_dir':train_dir, 'dev_dir':dev_dir, \n",
    "                'token_dir':token_dir, 'params_dir':params_dir}\n",
    "    \n",
    "training(dirs_dict, lr=0.001, decay=0., reg = 1e-4, batch_size = 120, epochs = 2, \n",
    "        max_len = 24, initial_epoch = 0, previous_model = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
