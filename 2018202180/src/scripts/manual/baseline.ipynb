{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bit4c03300bedca44f8b0013abe02048abc",
   "display_name": "Python 3.7.9 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('/home/peitian_zhang/Codes/NR')\n",
    "sys.path.append('/home/peitian_zhang/Codes/NR')\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.MIND import MIND_iter,MIND_map\n",
    "from utils.utils import getLoss,getLabel,constructBasicDict,run_eval,run_train\n",
    "from models.Soft_TopK import TopK_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'mode':'demo',\n",
    "    'name':'baseline',\n",
    "    'batch_size':5,\n",
    "    'title_size':20,\n",
    "    'his_size':100,\n",
    "    'npratio':4,\n",
    "    'dropout_p':0.2,\n",
    "    'query_dim':200,\n",
    "    'embedding_dim':300,\n",
    "    'value_dim':16,\n",
    "    'head_num':16,\n",
    "    'kernel_num':11,\n",
    "    'epochs':10,\n",
    "    'metrics':'group_auc,ndcg@4,mean_mrr',\n",
    "    'device':'cuda:0',\n",
    "    'attrs': ['title'],\n",
    "}\n",
    "\n",
    "news_file_train = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_train/news.tsv'\n",
    "news_file_test = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_dev/news.tsv'\n",
    "news_file_pair = (news_file_train,news_file_test)\n",
    "\n",
    "behavior_file_train = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_train/behaviors.tsv'\n",
    "behavior_file_test = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_dev/behaviors.tsv'\n",
    "behavior_file_pair = (behavior_file_train,behavior_file_test)\n",
    "\n",
    "save_path = 'models/model_params/{}_{}_{}'.format(hparams['name'],hparams['mode'],hparams['epochs']) +'.model'\n",
    "\n",
    "if not os.path.exists('data/dictionaries/vocab_{}_{}.pkl'.format(hparams['mode'],'_'.join(hparams['attrs']))):\n",
    "    constructBasicDict(news_file_pair,behavior_file_pair,hparams['mode'],hparams['attrs'])\n",
    "\n",
    "device = torch.device(hparams['device']) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "dataset_train = MIND_map(hparams=hparams,news_file=news_file_train,behaviors_file=behavior_file_train)\n",
    "\n",
    "dataset_test = MIND_iter(hparams=hparams,news_file=news_file_train,behaviors_file=behavior_file_train, mode='train')\n",
    "\n",
    "vocab = dataset_train.vocab\n",
    "embedding = GloVe(dim=300,cache='.vector_cache')\n",
    "vocab.load_vectors(embedding)\n",
    "\n",
    "loader_train = DataLoader(dataset_train,batch_size=hparams['batch_size'],shuffle=True,pin_memory=True,num_workers=3,drop_last=True)\n",
    "loader_test = DataLoader(dataset_test,batch_size=hparams['batch_size'],pin_memory=True,num_workers=0,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCAModel(nn.Module):\n",
    "    def __init__(self,hparams,vocab):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cdd_size = (hparams['npratio'] + 1) if hparams['npratio'] > 0 else 1\n",
    "        self.metrics = hparams['metrics']\n",
    "        self.device = torch.device(hparams['device']) if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.embedding = vocab.vectors\n",
    "\n",
    "        self.batch_size = hparams['batch_size']\n",
    "        self.signal_length = hparams['title_size']\n",
    "        self.his_size = hparams['his_size']\n",
    "\n",
    "        self.mus = torch.arange(-0.9,1.1,0.1,device=self.device)\n",
    "        self.kernel_num = len(self.mus)\n",
    "        self.sigmas = torch.tensor([0.1]*(self.kernel_num - 1) + [0.001], device=self.device)\n",
    "\n",
    "        self.head_num = hparams['head_num']\n",
    "        self.query_dim = hparams['query_dim']\n",
    "        self.embedding_dim = hparams['embedding_dim']\n",
    "        self.value_dim = hparams['value_dim']\n",
    "        self.repr_dim = self.head_num * self.value_dim\n",
    "        \n",
    "        self.query_words = nn.Parameter(torch.randn((1,self.query_dim), requires_grad=True))\n",
    "\n",
    "        # elements in the slice along dim will sum up to 1 \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.gumbel_softmax = nn.functional.gumbel_softmax\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.DropOut = nn.Dropout(p=hparams['dropout_p'])\n",
    "        self.CosSim = nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "        self.queryProject_words = nn.ModuleList([]).extend([nn.Linear(self.embedding_dim,self.embedding_dim, bias=False) for _ in range(self.head_num)])\n",
    "        self.valueProject_words = nn.ModuleList([]).extend([nn.Linear(self.embedding_dim,self.value_dim, bias=False) for _ in range(self.head_num)])\n",
    "        self.keyProject_words = nn.Linear(self.value_dim * self.head_num, self.query_dim, bias=True)\n",
    "        self.learningToRank = nn.Linear(self.kernel_num, 1)\n",
    "\n",
    "    def _scaled_dp_attention(self,query,key,value):\n",
    "        \"\"\" calculate scaled attended output of values\n",
    "        \n",
    "        Args:\n",
    "            query: tensor of [batch_size, *, query_num, key_dim]\n",
    "            key: tensor of [batch_size, *, key_num, key_dim]\n",
    "            value: tensor of [batch_size, *, key_num, value_dim]\n",
    "        \n",
    "        Returns:\n",
    "            attn_output: tensor of [batch_size, *, query_num, value_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        # make sure dimension matches\n",
    "        assert query.shape[-1] == key.shape[-1]\n",
    "        key = key.transpose(-2,-1)\n",
    "\n",
    "        attn_weights = torch.matmul(query,key)/math.sqrt(self.embedding_dim)\n",
    "        attn_weights = self.softmax(attn_weights)\n",
    "        \n",
    "        attn_output = torch.matmul(attn_weights,value)\n",
    "\n",
    "        return attn_output\n",
    "\n",
    "    def _self_attention(self,input,head_idx):\n",
    "        \"\"\" apply self attention of head#idx over input tensor\n",
    "        \n",
    "        Args:\n",
    "            input: tensor of [batch_size, *, embedding_dim]\n",
    "            head_idx: interger of attention head index\n",
    "\n",
    "        Returns:\n",
    "            self_attn_output: tensor of [batch_size, *, embedding_dim]\n",
    "        \"\"\"\n",
    "        query = self.queryProject_words[head_idx](input)\n",
    "\n",
    "        attn_output = self._scaled_dp_attention(query,input,input)\n",
    "        self_attn_output = self.valueProject_words[head_idx](attn_output)\n",
    "\n",
    "        return self_attn_output\n",
    "    \n",
    "    def _word_attention(self, query, key, value):\n",
    "        \"\"\" apply word-level attention\n",
    "\n",
    "        Args:\n",
    "            attn_word_embedding_key: tensor of [batch_size, *, signal_length, query_dim]\n",
    "            attn_word_embedding_value: tensor of [batch_size, *, signal_length, repr_dim]\n",
    "        \n",
    "        Returns:\n",
    "            attn_output: tensor of [batch_size, *, repr_dim]\n",
    "        \"\"\"\n",
    "        query = query.expand(key.shape[0], key.shape[1], 1, self.query_dim)\n",
    "\n",
    "        attn_output = self._scaled_dp_attention(query,key,value).squeeze(dim=2)\n",
    "\n",
    "        return attn_output\n",
    "\n",
    "\n",
    "    def _multi_head_self_attention(self,input):\n",
    "        \"\"\" apply multi-head self attention over input tensor\n",
    "\n",
    "        Args:\n",
    "            input: tensor of [batch_size, *, signal_length, embedding_dim]\n",
    "        \n",
    "        Returns:\n",
    "            multi_head_self_attn: tensor of [batch_size, *, 1, repr_dim]\n",
    "        \"\"\"\n",
    "        self_attn_outputs = [self._self_attention(input,i) for i in range(self.head_num)]\n",
    "\n",
    "        # project the embedding of each words to query subspace\n",
    "        # keep the original embedding of each words as values\n",
    "        multi_head_self_attn_value = torch.cat(self_attn_outputs,dim=-1)\n",
    "        multi_head_self_attn_key = torch.tanh(self.keyProject_words(multi_head_self_attn_value))\n",
    "\n",
    "        additive_attn_embedding = self._word_attention(self.query_words, multi_head_self_attn_key,multi_head_self_attn_value)\n",
    "        return additive_attn_embedding\n",
    "\n",
    "    def _news_encoder(self,news_batch):\n",
    "        \"\"\" encode set of news to news representations of [batch_size, cdd_size, tranformer_dim]\n",
    "        \n",
    "        Args:\n",
    "            news_batch: tensor of [batch_size, cdd_size, title_size]\n",
    "            word_query: tensor of [set_size, preference_dim]\n",
    "        \n",
    "        Returns:\n",
    "            news_repr_attn: tensor of [batch_size, cdd_size, repr_dim]\n",
    "            news_repr_origin: tensor of [batch_size, cdd_size, signal_length, embedding_dim] \n",
    "        \"\"\"\n",
    "        news_embedding_origin = self.DropOut(self.embedding[news_batch].to(self.device))\n",
    "        news_embedding_attn = self._multi_head_self_attention(news_embedding_origin)\n",
    "        return news_embedding_attn, news_embedding_origin\n",
    "\n",
    "    def _kernel_pooling(self,matrixs):\n",
    "        \"\"\"\n",
    "            apply kernel pooling on matrix, in order to get the relatedness from many levels\n",
    "        \n",
    "        Args:\n",
    "            matrix: tensor of [batch_size, rows, columns]\n",
    "        \n",
    "        Returns:\n",
    "            pooling_vectors: tensor of [batch_size, kernel_num]\n",
    "        \"\"\"\n",
    "        pooling_matrixs = torch.zeros(matrixs.shape[0],matrixs.shape[1],self.kernel_num,device=self.device)\n",
    "        \n",
    "        for k in range(self.kernel_num):\n",
    "            pooling_matrixs[:,:,k] = torch.sum(torch.exp(-(matrixs - self.mus[k])**2 / (2*self.sigmas[k]**2)),dim=2)\n",
    "        \n",
    "        pooling_vectors = torch.sum(torch.log(torch.clamp(pooling_matrixs,min=1e-10)),dim=1)\n",
    "        return pooling_vectors\n",
    "\n",
    "    def _news_attention(self, cdd_attn, his_attn, his_org, his_mask):\n",
    "        \"\"\" apply news-level attention\n",
    "\n",
    "        Args:\n",
    "            cdd_attn: tensor of [batch_size, cdd_size, repr_dim]\n",
    "            his_attn: tensor of [batch_size, his_size, repr_dim]\n",
    "            his_org: tensor of [batch_size, his_size, signal_length, embedding_dim]\n",
    "            his_mask: tensor of [batch_size, his_size, 1]            \n",
    "\n",
    "        Returns:\n",
    "            his_activated: tensor of [batch_size, cdd_size, signal_length, embedding_dim]\n",
    "        \"\"\"\n",
    "        attn_weights = torch.bmm(cdd_attn,his_attn.permute(0,2,1))\n",
    "\n",
    "        # print(attn_weights)\n",
    "\n",
    "        # padding in history will cause 0 in attention weights, underlying the probability that gumbel_softmax may attend to those meaningless 0 vectors. Masking off these 0s will force the gumbel_softmax to attend to only non-zero histories.\n",
    "        # mask in candidate also cause such a problem, however we donot need to fix it, because the whole row of attention weight matrix is zero so gumbel_softmax can only capture 0 vectors, though reuslting in redundant calculation but it is what we want of padding 0 to negtive sampled candidates as they may be less than npratio.\n",
    "        attn_weights =  attn_weights.masked_fill(his_mask.permute(0,2,1), -float(\"inf\"))\n",
    "        # print(attn_weights)\n",
    "        # [batch_size, cdd_size, his_size]\n",
    "        attn_focus = self.gumbel_softmax(attn_weights,dim=2,hard=True)\n",
    "\n",
    "        # print(attn_focus)\n",
    "\n",
    "        # [batch_size * cdd_size, signal_length * embedding_dim]\n",
    "        his_activated = torch.matmul(attn_focus,his_org.view(self.batch_size,self.his_size,-1)).view(self.batch_size,self.cdd_size,self.signal_length,self.embedding_dim)\n",
    "        \n",
    "        return his_activated\n",
    "    \n",
    "    def _fusion(self,his_activated,cdd_org):\n",
    "        \"\"\" fuse activated history news and candidate news into interaction matrix, words in history is column and words in candidate is row, then apply KNRM on each interaction matrix\n",
    "\n",
    "        Args:\n",
    "            his_activated: tensor of [batch_size, cdd_size, signal_length, embedding_dim]\n",
    "            cdd_org: tensor of [batch_size, cdd_size, signal_length, embedding_dim]\n",
    "        \n",
    "        Returns:\n",
    "            pooling_vector: tensor of [batch_size, cdd_size, kernel_num]\n",
    "        \"\"\"\n",
    "\n",
    "        fusion_matrixs = torch.zeros((self.batch_size, self.cdd_size, self.signal_length, self.signal_length), device=self.device)\n",
    "        for i in range(self.signal_length):\n",
    "            fusion_matrixs[ :, :, i, :] = self.CosSim(cdd_org[ :, :, i, :].unsqueeze(2), his_activated)\n",
    "        \n",
    "        # print(fusion_matrixs, fusion_matrixs.shape)\n",
    "        pooling_vectors = self._kernel_pooling(fusion_matrixs.view(-1,self.signal_length,self.signal_length)).view(self.batch_size, -1, self.kernel_num)\n",
    "\n",
    "        assert pooling_vectors.shape[1] == self.cdd_size or pooling_vectors.shape[1] == 1\n",
    "        \n",
    "        return pooling_vectors\n",
    "    \n",
    "    def _click_predictor(self,pooling_vectors):\n",
    "        \"\"\" calculate batch of click probability              \n",
    "        Args:\n",
    "            pooling_vectors: tensor of [batch_size, cdd_size, kernel_num]\n",
    "        \n",
    "        Returns:\n",
    "            score: tensor of [batch_size, cdd_size]\n",
    "        \"\"\"\n",
    "        score = self.learningToRank(pooling_vectors)\n",
    "\n",
    "        if self.cdd_size > 1:\n",
    "            score = nn.functional.log_softmax(score,dim=1)\n",
    "        else:\n",
    "            score = torch.sigmoid(score)\n",
    "        \n",
    "        return score.squeeze()\n",
    "\n",
    "    def forward(self,x):\n",
    "        cdd_news_embedding_attn,cdd_news_embedding_origin = self._news_encoder(x['candidate_title'].long().to(self.device))\n",
    "        his_news_embedding_attn,his_news_embedding_origin = self._news_encoder(x['clicked_title'].long().to(self.device))\n",
    "\n",
    "        # mask the history news \n",
    "        click_mask = x['click_mask'].to(self.device)\n",
    "\n",
    "        his_activated = self._news_attention(cdd_news_embedding_attn,his_news_embedding_attn,his_news_embedding_origin, click_mask)\n",
    "        pooling_vectors = self._fusion(his_activated,cdd_news_embedding_origin)\n",
    "\n",
    "        # print(pooling_vectors,pooling_vectors.shape)\n",
    "        score_batch = self._click_predictor(pooling_vectors)\n",
    "        # print(score_batch,score_batch.shape)\n",
    "        return score_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GCAModel(\n",
       "  (softmax): Softmax(dim=-1)\n",
       "  (ReLU): ReLU()\n",
       "  (DropOut): Dropout(p=0.2, inplace=False)\n",
       "  (CosSim): CosineSimilarity()\n",
       "  (queryProject_words): ModuleList(\n",
       "    (0): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (1): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (2): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (3): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (4): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (5): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (6): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (7): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (8): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (9): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (10): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (11): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (12): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (13): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (14): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (15): Linear(in_features=300, out_features=300, bias=False)\n",
       "  )\n",
       "  (valueProject_words): ModuleList(\n",
       "    (0): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (1): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (2): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (3): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (4): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (5): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (6): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (7): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (8): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (9): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (10): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (11): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (12): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (13): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (14): Linear(in_features=300, out_features=16, bias=False)\n",
       "    (15): Linear(in_features=300, out_features=16, bias=False)\n",
       "  )\n",
       "  (keyProject_words): Linear(in_features=256, out_features=200, bias=True)\n",
       "  (learningToRank): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# gcaModel = GCAModel(vocab=vocab,hparams=hparams).to(device)\n",
    "# gcaModel.load_state_dict(torch.load(save_path))\n",
    "# gcaModel.eval()\n",
    "\n",
    "gcaModel = GCAModel(vocab=vocab,hparams=hparams).to(device)\n",
    "gcaModel.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training...\n",
      "epoch 0 , step 390 , loss: 4.4599: : 400it [00:25, 15.56it/s]\n",
      "epoch 1 , step 180 , loss: 1.7435: : 187it [00:11, 15.79it/s]"
     ]
    }
   ],
   "source": [
    "if gcaModel.training:\n",
    "    print(\"training...\")\n",
    "    loss_func = getLoss(gcaModel)\n",
    "    optimizer = optim.Adam(gcaModel.parameters(),lr=0.001)\n",
    "    gcaModel = run_train(gcaModel,loader_train,optimizer,loss_func,epochs=2, interval=10, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "15062it [10:30, 23.90it/s]\n",
      "evaluation results:{'group_auc': 0.5, 'ndcg@4': 0.211, 'mean_mrr': 0.2218}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'group_auc': 0.5, 'ndcg@4': 0.211, 'mean_mrr': 0.2218}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "gcaModel.eval()\n",
    "gcaModel.vocab = vocab\n",
    "gcaModel.cdd_size = 1\n",
    "\n",
    "run_eval(gcaModel,loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcaModel.cdd_size = 5\n",
    "torch.save(gcaModel.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}