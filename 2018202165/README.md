# 基于内容的新闻推荐—DKN算法实践

[TOC]



## 推荐系统及算法简介

### 推荐系统概述

在这个时代，无论是信息消费者还是信息生产者都遇到了很大的挑战:作为信息消费者，如何从大量信息中找到自己感兴趣的信息是一件非常困难的事情;作为信息生产者， 如何让自己生产的信息脱颖而出，受到广大用户的关注，也是一件非常困难的事情。推荐系统就是解决这一矛盾的重要工具。推荐系统的任务就是联系用户和信息，一方面帮助用户发现对自己有价值的信息，另一方面让信息能够展现在对它感兴趣的用户面前，从而实现信息消费者和信息 生产者的双赢。

和搜索引擎不同的是，推荐系统不需要用户提供明确的需求，而是通过分析用户的历史行为给用 户的兴趣建模，从而主动给用户推荐能够满足他们兴趣和需求的信息。



### 推荐算法概述

#### 协同过滤推荐

协调过滤是推荐算法中目前最主流的种类，花样繁多，在工业界已经有了很多广泛的应用。它的优点是**不需要太多特定领域的知识，可以通过基于统计的机器学习算法来得到较好的推荐效果**。最大的优点是工程上容易实现，可以方便应用到产品中。目前绝大多数实际应用的推荐算法都是协同过滤推荐算法。



#### 混合推荐

这个类似机器学习中的集成学习，博才众长，通过多个推荐算法的结合，得到一个更好的推荐算法，起到三个臭皮匠顶一个诸葛亮的作用。比如通过建立多个推荐算法的模型，最后用投票法决定最终的推荐结果。



#### 基于规则的推荐

这类算法常见的比如**基于最多用户点击，最多用户浏览**等，属于大众型的推荐方法，在目前的大数据时代并不主流。



#### 基于人口信息的推荐

这一类是最简单的推荐算法了，它只是简单的根据系统用户的基本信息发现用户的相关程度，然后进行推荐，目前在大型系统中已经较少使用。



#### 基于内容的推荐

这一类一般**依赖于自然语言处理NLP的一些知识，通过挖掘文本的TF-IDF特征向量，来得到用户的偏好**，进而做推荐。这类推荐算法可以找到用户独特的小众喜好，而且还有**较好的解释性**。





## DKN算法简介

DKN算法是一种基于内容的新闻推荐算法。本次实验是目标在于完成DKN算法的搭建。



### 问题定义

新闻标题和正文中通常存在大量的实体，实体间的语义关系可以有效地扩展用户兴趣。然而这种语义关系难以被传统方法（话题模型、词向量）发掘。

对于一个给定的用户user~i~，他的点击历史t = {W~1~，W~2~，……，W~n~}，记为是该用户过去一段时间内曾点击过的新闻的标题，N代表用户点击过的新闻的总数。每个标题都是一个词序列，标题中的单词有的对应知识图谱中的一个实体。举例来说，标题《Trump praises Las Vegas medical team》其中Trump与知识图谱中的实体“Donald Trump”对应，Las和Vegas与实体Las Vegas对应。本文要解决的问题就是给定用户的点击历史，以及标题单词和知识图谱中实体的关联，要预测的是：一个用户i是否会点击一个特定的新闻t~j~。



### DKN模型

<img src="https://recodatasets.blob.core.windows.net/images/dkn_architecture.png" alt="img" style="zoom:80%;" />



上图为DKN模型算法流程图，我们将在下面详细介绍此模型。

DKN的网络输入有两个：候选新闻集合，用户点击过的新闻标题序列。输入数据通过KCNN来提取特征，之上是一个attention层，计算候选新闻向量与用户点击历史向量之间的attention权重，在顶层拼接两部分向量之后，用DNN计算用户点击此新闻的概率。



KCNN：

Kim CNN，用句子所包含词的词向量组成的二维矩阵，经过一层卷积操作之后再做一次max-over-time的pooling操作得到句子向量。
三种向量**词向量、实体向量、上下文向量**（实体第一层的关联实体的向量），简单的concat，然后通过两种不同size的卷积池化，再将两种size的结果concat。

（１）输入层
如图所示，输入层是句子中的词语对应的wordvector依次排列的矩阵，假设句子有 n 个词，vector的维数为  k  ，那么这个矩阵就是  n × k 的(在CNN中可以看作一副高度为n、宽度为k的图像)。

（２）第一层卷积
输入层通过卷积操作得到若干个Feature Map，卷积窗口的大小为 h ×k ，其中 h  表示纵向词语的个数，而  k  表示word vector的维数。通过这样一个大型的卷积窗口，将得到若干个列数为1的Feature Map。

（３）池化层
接下来的池化层，文中用了一种称为Max-over-time Pooling的方法。这种方法就是简单地从之前一维的Feature Map中提出最大的值，文中解释最大值代表着最重要的信号。可以看出，这种Pooling方式可以解决可变长度的句子输入问题（因为不管Feature Map中有多少个值，只需要提取其中的最大值）。最终池化层的输出为各个Feature Map的最大值们，即一个一维的向量。



Attention：

简单来说，就是一种权重参数的分配机制，目标是协助模型捕捉重要信息。具体一点就是，给定一组<key,value>，以及一个目标（查询）向量query，attention机制就是通过计算query与每一组key的相似性，得到每个key的权重系数，再通过对value加权求和，得到最终attention数值。
获取到用户点击过的每篇新闻的向量表示以后，计算候选文档对于用户每篇点击文档的attention，再做加权求和，计算attention。



## 我们目前的工作

项目学习来源于，项目环境搭建也依赖于其中的指示，但是，仅仅针对我们的工作而言，我们并不需要项目中的全部的环境依赖，在项目完成之时，我们会针对我们的需求详细写出一份环境依赖搭建的指示。

我们选择其中examples\02_model_content_based_filtering\dkn_deep_dive.ipynb文件学习并重现其工作内容，不可避免的，我们也会按照我们的需求暂时进行改动。

截止前三周（10.9——10.30），我们通过有关书籍学习深度学习理论知识，利用tensorflow进行网络搭建，并完成了数据准备工作，在项目文件夹src的dataset.py，该文件为一个可执行文件，会将项目数据进行清洗集成并输出至文件中。

我们将会在以后的提交中展现更多内容，敬请期待……
