{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "import numpy as np\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import pdb\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, pool='max', drop_p=0):\n",
    "        super(CNN, self).__init__()\n",
    "        self.drop_p = drop_p\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.cnn2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        if pool == 'max':\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        else:\n",
    "            self.pool = nn.AvgPool2d(kernel_size=2)\n",
    "\n",
    "        if self.drop_p:\n",
    "            self.drop = nn.Dropout(p=self.drop_p)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 23, 512)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 40)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_p:\n",
    "            out = self.pool(self.drop(self.relu1(self.bn1(self.cnn1(x)))))\n",
    "            out = self.pool(self.drop(self.relu2(self.bn2(self.cnn2(out)))))\n",
    "            out = out.view(out.size(0), -1)\n",
    "            out = self.fc2(self.drop(self.relu6(self.fc1(out))))\n",
    "        else:\n",
    "            out = self.pool(self.relu1(self.bn1(self.cnn1(x))))\n",
    "            out = self.pool(self.relu2(self.bn2(self.cnn2(out))))\n",
    "            out = out.view(out.size(0), -1)\n",
    "            out = self.fc2(self.relu6(self.fc1(out)))\n",
    "        return out\n",
    "\n",
    "    def cnn1_out(self, x):\n",
    "        return self.cnn1(x)\n",
    "\n",
    "    def cnn2_out(self, x):\n",
    "        if self.drop_p:\n",
    "            out = self.pool(self.drop(self.relu1(self.bn1(self.cnn1(x)))))\n",
    "        else:\n",
    "            out = self.pool(self.relu1(self.bn1(self.cnn1(x))))\n",
    "        return self.cnn2(out)\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, model, epochs, lr, batch_size, use_gpu=False, optim='adam', reg=None):\n",
    "        '''\n",
    "        model: instance of pytorch model class\n",
    "        epochs: number of training epochs\n",
    "        lr: learning rate\n",
    "        use_gpu: to use gpu\n",
    "        optim: optimizer used for training, SGD or adam\n",
    "        '''\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.model = model\n",
    "        self.use_gpu = use_gpu\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        self.test_acc = []\n",
    "        self.train_iter_loss = []\n",
    "        self.reg = reg\n",
    "        self.batch_size = batch_size\n",
    "        self.optim = optim\n",
    "        if self.use_gpu:\n",
    "            self.model = self.model.cuda()\n",
    "        #可尝试不同优化器\n",
    "        if optim == 'adam':\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        elif optim == 'sgd':\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr, momentum=0.9)\n",
    "        elif optim == 'adadelta':\n",
    "            self.optimizer = torch.optim.Adadelta(self.model.parameters(),\n",
    "                                                  lr=lr, eps=1e-6,\n",
    "                                                  weight_decay=0)\n",
    "        elif optim == 'adagrad':\n",
    "            self.optimizer = torch.optim.Adagrad(self.model.parameters(), lr=lr,\n",
    "                                                 lr_decay=1e-6, weight_decay=0)\n",
    "        elif optim == 'rmsprop':\n",
    "            self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr=lr,\n",
    "                                                 alpha=0.995, eps=1e-7,\n",
    "                                                 weight_decay=0)\n",
    "        else:\n",
    "            ValueError('Optimizer Not Supported')\n",
    "\n",
    "    def train(self, epoch, trainloader, print_every=100):\n",
    "        '''\n",
    "        method for training\n",
    "        '''\n",
    "        self.model.train()\n",
    "        loss_batch = 0\n",
    "        for b_idx, (train_data, train_labels) in enumerate(trainloader):\n",
    "            shape = train_data.shape\n",
    "            train_data = train_data.view(shape[0], 1, shape[1], shape[2])\n",
    "            if self.use_gpu:\n",
    "                train_data, train_labels = train_data.cuda(), train_labels.cuda()\n",
    "            # Forward Pass \n",
    "            train_preds = self.model.forward(train_data)\n",
    "            loss = self.model.loss(train_preds, train_labels)\n",
    "            if self.reg == 'l2':\n",
    "                loss = self.regularization(loss, lam=0.0001, reg='l2')\n",
    "            elif self.reg == 'l1':\n",
    "                loss = self.regularization(loss, lam=0.000001, reg='l1')\n",
    "            else:\n",
    "                pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if b_idx % print_every == 0:\n",
    "                print('Train Epoch: {0} [{1}/{2} ({3:.0f}%)]\\t Loss {4:.6f}'.\n",
    "                      format(epoch, b_idx * len(train_data), len(trainloader.dataset),\n",
    "                             100. * b_idx / len(trainloader), loss))\n",
    "\n",
    "            train_loss = loss.item()\n",
    "            self.train_iter_loss.append(train_loss)\n",
    "            loss_batch += train_loss\n",
    "        loss_batch /= len(trainloader)\n",
    "        self.train_loss.append(loss_batch)\n",
    "\n",
    "    def test(self, testloader):\n",
    "        '''\n",
    "        method for testing\n",
    "        '''\n",
    "        self.model.eval()\n",
    "        correct_, total_ = 0, 0\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for test_data, test_labels in testloader:\n",
    "                shape = test_data.shape\n",
    "                test_data = test_data.view(shape[0], 1, shape[1], shape[2])\n",
    "                if self.use_gpu:\n",
    "                    test_data, test_labels = test_data.cuda(), test_labels.cuda()\n",
    "                test_preds = self.model.forward(test_data)\n",
    "\n",
    "                loss += self.model.loss(test_preds, test_labels)\n",
    "\n",
    "                _, test_pred_labels = torch.max(test_preds.data, 1)\n",
    "                total_ += test_labels.size(0)\n",
    "                correct_ += (test_pred_labels.cpu() == test_labels.cpu()).sum()\n",
    "\n",
    "            loss /= len(testloader)\n",
    "            self.test_loss.append(loss)\n",
    "            \n",
    "            accuracy_test = torch.true_divide(100 * correct_ , total_)\n",
    "            self.test_acc.append(accuracy_test)\n",
    "            print('Accuracy of model on test set {0:.2f}'.format(accuracy_test))\n",
    "            return accuracy_test\n",
    "\n",
    "    def evaluator(self, trainloader, testloader, print_every=1000):\n",
    "        for epoch in range(self.epochs):\n",
    "            self.train(epoch, trainloader, print_every=print_every)\n",
    "            if epoch % 5 == 0:\n",
    "                save_model = {'epoch': epoch,\n",
    "                              'state_dict': self.model.state_dict(),\n",
    "                              'optimizer': self.optimizer.state_dict()}\n",
    "            model_name = 'Model_lr_{}_opt_{}_epoch_{}'.format(self.lr, self.optim, epoch)\n",
    "            model_dir = 'model/' +model_name\n",
    "            torch.save(save_model, model_dir)\n",
    "            acc_ = self.test(testloader)\n",
    "        return acc_\n",
    "\n",
    "    def regularization(self, loss, lam, reg='l2'):\n",
    "        ll = torch.tensor(0.0)\n",
    "        for W in self.model.parameters():\n",
    "            if reg == 'l2':\n",
    "                ll += W.norm(2)\n",
    "            else:\n",
    "                ll += W.norm(1)\n",
    "        loss = loss + 0.5 * lam * ll ** 2\n",
    "        return loss\n",
    "\n",
    "    def plot_loss(self):\n",
    "        '''\n",
    "        to visualize loss\n",
    "        '''\n",
    "        plt.plot(range(len(self.train_loss)), self.train_loss, label='Training Loss')\n",
    "        plt.plot(range(len(self.test_loss)), self.test_loss, label='Testing Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        return plt\n",
    "\n",
    "    def plot_acc(self):\n",
    "\n",
    "        plt.plot(range(len(self.test_acc)), self.test_acc, label='Testing Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        return plt\n",
    "\n",
    "    def plot_iter_loss(self):\n",
    "        '''\n",
    "        to visualize loss\n",
    "        '''\n",
    "        plt.plot(range(len(self.train_iter_loss)), self.train_iter_loss, label='Training Loss')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def vistensor(tensor, ch=0, nrow=20, padding=1):\n",
    "    '''\n",
    "    https://github.com/pedrodiamel/nettutorial/blob/master/pytorch/pytorch_visualization.ipynb\n",
    "    '''\n",
    "\n",
    "    n, c, w, h = tensor.shape\n",
    "    if c != 3:\n",
    "        tensor = tensor.view(n * c, -1, w, h)\n",
    "        tensor = tensor[:, ch, :, :].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))\n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure(figsize=(nrow, rows))\n",
    "    plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "\n",
    "def plot_img(tensor, num_cols=10):\n",
    "    num_kernels = tensor.shape[0]\n",
    "    num_rows = 1 + num_kernels // num_cols\n",
    "    fig = plt.figure(figsize=(num_cols, num_rows))\n",
    "    for i in range(num_kernels):\n",
    "        ax1 = fig.add_subplot(num_rows, num_cols, i + 1)\n",
    "        ax1.imshow(tensor[i], cmap='gray')\n",
    "        ax1.axis('off')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/120 (0%)]\t Loss 3.837313\n",
      "Accuracy of model on test set 7.50\n",
      "Train Epoch: 1 [0/120 (0%)]\t Loss 21.578197\n",
      "Accuracy of model on test set 15.83\n",
      "Train Epoch: 2 [0/120 (0%)]\t Loss 13.842201\n",
      "Accuracy of model on test set 43.33\n",
      "Train Epoch: 3 [0/120 (0%)]\t Loss 3.742854\n",
      "Accuracy of model on test set 82.50\n",
      "Train Epoch: 4 [0/120 (0%)]\t Loss 1.303545\n",
      "Accuracy of model on test set 95.00\n",
      "Train Epoch: 5 [0/120 (0%)]\t Loss 0.653032\n",
      "Accuracy of model on test set 100.00\n",
      "Train Epoch: 6 [0/120 (0%)]\t Loss 0.767896\n",
      "Accuracy of model on test set 99.17\n",
      "Train Epoch: 7 [0/120 (0%)]\t Loss 0.269186\n",
      "Accuracy of model on test set 100.00\n",
      "Train Epoch: 8 [0/120 (0%)]\t Loss 0.110186\n",
      "Accuracy of model on test set 100.00\n",
      "Train Epoch: 9 [0/120 (0%)]\t Loss 0.130367\n",
      "Accuracy of model on test set 100.00\n",
      "Accuracy of model_optimizer_adam_lr_0.001_drop_p_ is 100.00\n",
      "torch.Size([32, 1, 3, 3])\n",
      "torch.Size([64, 32, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x144 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x144 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# load data\n",
    "data = np.load('ORL_face.npz')\n",
    "trainX = data['trainX']\n",
    "trainY = data['trainY']\n",
    "testX = data['testX']\n",
    "testY = data['testY']\n",
    "\n",
    "train_images, test_images = trainX.shape[0], testX.shape[0]\n",
    "trainX = trainX.astype(np.float32).reshape(train_images, 112, 92)\n",
    "testX = testX.astype(np.float32).reshape(test_images, 112, 92)\n",
    "trainY = trainY.astype(np.longlong)\n",
    "testY = testY.astype(np.longlong)\n",
    "\n",
    "#trainY =torch.LongTensor(trainY)\n",
    "#testY =torch.LongTensor(testY)\n",
    "#print(trainY.dtype)\n",
    "# Image Sanity check\n",
    "sample_set = np.random.randint(0, train_images, 50)\n",
    "plt = plot_img(trainX[sample_set])\n",
    "plt.savefig('sanity_check_img_plot')\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "trainX = torch.from_numpy(trainX)\n",
    "trainY = torch.from_numpy(trainY)\n",
    "testX = torch.from_numpy(testX)\n",
    "testY = torch.from_numpy(testY) \n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(trainX, trainY)\n",
    "test_data = torch.utils.data.TensorDataset(testX, testY)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "\n",
    "drop_p = 0.3\n",
    "n_in = trainX.shape[1]\n",
    "n_out = len(np.unique(trainY))\n",
    "\n",
    "pool = 'max'\n",
    "optim = 'adam'\n",
    "use_gpu = False\n",
    "\n",
    "model = CNN(pool, drop_p=drop_p)\n",
    "modeleval = ModelEvaluator(model, epochs, lr, batch_size, use_gpu=use_gpu, optim=optim)\n",
    "acc_ = modeleval.evaluator(train_loader, test_loader, print_every=100)\n",
    "\n",
    "modelname = 'model_optimizer_{}_lr_{}_drop_p_'.format(optim, lr)\n",
    "print('Accuracy of {0} is {1:.2f}'.format(modelname, acc_))\n",
    "\n",
    "\n",
    "plt = modeleval.plot_loss()\n",
    "plt.savefig('train_test_loss, optim_{}_lr_{}_drop_p_{}.png'.format(optim, lr, drop_p))\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "plt = modeleval.plot_acc()\n",
    "plt.savefig('test_acc, optim_{}, _lr_{}_drop_p_{}.png'.format(optim, lr, drop_p))\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "\n",
    "plt = modeleval.plot_iter_loss()\n",
    "plt.savefig('train_iterloss, optim_{}, _lr_{}_drop_p_{}.png'.format(optim, lr, drop_p))\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "# Visualize Kernels\n",
    "\n",
    "filters = model.modules()\n",
    "model_layers = [i for i in model.children()]\n",
    "first_layer = model_layers[0]\n",
    "second_layer = model_layers[3]\n",
    "\n",
    "first_kernels = first_layer.weight.data.clone()\n",
    "print(first_kernels.shape)\n",
    "vistensor(first_kernels)\n",
    "plt.axis('off')\n",
    "plt.ioff()\n",
    "plt.savefig('filter conv 1 optim_{}_lr_{}_drop_p_{}.png'.format(optim, lr, drop_p))\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "second_kernels = second_layer.weight.data.clone()\n",
    "print(second_kernels.shape)\n",
    "vistensor(second_kernels[0, ...].reshape(1, 32, 3, 3))\n",
    "plt.axis('off')\n",
    "plt.ioff()\n",
    "plt.savefig('filter conv 2 optim_{}_lr_{}_drop_p_{}.png'.format(optim, lr, drop_p))\n",
    "plt.cla()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001E448EEE088>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
